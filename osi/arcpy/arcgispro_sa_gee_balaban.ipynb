{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install earthengine-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trigger the authentication flow. if you want to user json, please comment this\n",
    "ee.Authenticate()\n",
    "# Initialize the library\n",
    "# ee.Initialize(project='bukit30project')\n",
    "ee.Initialize(project='ee-iwansetiawan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install geemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_dir:  C:\\Users\\q_bal\\Documents\\Github\\GEE_notebook_Forestry\\osi/qgis\n",
      "config--->  {'module_path': 'C:/Users/q_bal/Documents/Github/GEE_notebook_Forestry', 'I_satellite': 'Planet', 'pca_scaling': 1, 'tileScale': 1, 'AOI_path': 'G:/Shared drives/TREEO BD Supply/satellite_verification/PPP/LPHD Belaban Rayak.shp', 'OID_field_name': 'id', 'input_training': 'G:/Shared drives/TREEO BD Supply/satellite_verification/PPP/traning_point_merged_belaban.shp', 'algo_ml_selected': 'gbm', 'date_start_end': ['2024-5-1', '2024-5-31'], 'project_name': 'belaban_rayak', 'super_pixel_size': 3, 'region': 'asia', 'pixel_number': 3, 'year_start_loss': 14, 'tree_cover_forest': 30, 'band_name_image': 'Class', 'cloud_cover_threshold': 40, 'crs_input': 'EPSG:4326', 'IsThermal': False, 'fcd_selected': 21, 'high_forest': 65, 'yrf_forest': 45, 'shrub_grass': 45, 'open_land': 30, 'ndwi_hi_sentinel': 0.05, 'ndwi_hi_landsat': 0.1, 'ndwi_hi_planet': -0.2}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "\n",
    "# variable\n",
    "# Connect to the path of the module\n",
    "module_path = r'C:\\Users\\q_bal\\Documents\\Github\\GEE_notebook_Forestry'\n",
    "map_name_arcgis_pro = 'eligibility_check_prospective_tpps'\n",
    "create_training_gee = False\n",
    "\n",
    "# Add the module path to sys.path\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "current_dir = os.path.join(module_path,\"osi/qgis\")\n",
    "print('current_dir: ',current_dir)\n",
    "\n",
    "# Move to the parent directory of the current script\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# Construct the absolute path to the JSON file in the 'input' folder\n",
    "json_path= os.path.join(parent_dir, '00_input', 'balaban_conf.json')\n",
    "\n",
    "# Read and load the JSON data from the file\n",
    "with open(json_path, 'r') as file:\n",
    "    config = json.load(file)\n",
    "\n",
    "print('config---> ',config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import main library\n",
    "import ee\n",
    "import geemap\n",
    "import osi\n",
    "import pandas as pd\n",
    "\n",
    "from osi.utils.main import validate_aoi\n",
    "# convert the modules for image collection (cloudless masking, compositing, reducer etc)\n",
    "from osi.image_collection.main import ImageCollection\n",
    "from osi.spectral_indices.spectral_analysis import SpectralAnalysis\n",
    "from osi.spectral_indices.utils import normalization_100\n",
    "from osi.hansen.historical_loss import HansenHistorical\n",
    "from osi.classifying.assign_zone import AssignClassZone\n",
    "from osi.legends.utils import convert_to_legend_items\n",
    "from osi.legends.main import LegendsBuilder\n",
    "from osi.obia.main import OBIASegmentation\n",
    "from osi.ml.main import LandcoverML\n",
    "from osi.arcpy.main import ArcpyOps\n",
    "from osi.fcd.main_fcd import FCDCalc\n",
    "from osi.pca.pca_gee import PCA\n",
    "from osi.hansen.historical_loss import HansenHistorical\n",
    "from osi.classifying.assign_zone import AssignClassZone\n",
    "\n",
    "\n",
    "AOIt_shp_plot = geemap.shp_to_ee(config['AOI_path'])\n",
    "crs_input = config['crs_input']\n",
    "I_satellite = config['I_satellite']\n",
    "project_name = config['project_name']\n",
    "\n",
    "start_date = config['date_start_end'][0]\n",
    "end_date = config['date_start_end'][1]\n",
    "\n",
    "layer_name_image_mosaick = f'image_mosaick_result_ee_{project_name}'\n",
    "\n",
    "AOI = AOIt_shp_plot\n",
    "config['AOI'] = AOI\n",
    "\n",
    "ndwi_hi = 0.1\n",
    "if config['I_satellite'] == 'Landsat':\n",
    "    ndwi_hi = config['ndwi_hi_landsat']\n",
    "elif I_satellite == 'Sentinel':\n",
    "    ndwi_hi = config['ndwi_hi_sentinel']\n",
    "elif I_satellite == 'Planet':\n",
    "    ndwi_hi = config['ndwi_hi_planet']\n",
    "\n",
    "### Masking and overlay and area helper Make an image out of the AOI area attribute -> convert featurecollection into raster (image) for overlaying tools\n",
    "OID = config['OID_field_name']\n",
    "AOI_img = AOI.filter(ee.Filter.notNull([OID])).reduceToImage(\n",
    "    properties= [OID],\n",
    "    reducer= ee.Reducer.first()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pycrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD FIRST AOI TO ARCGIS MAP - option-1 in using existing shp to geemap\n",
    "# aoi_layer_name_in_map_arcgis = 'aoi_extent_delight'\n",
    "\n",
    "# USE THE PATH FOR TRAINING DATA - option-2 in using existing shp to geemap\n",
    "# path_shp_input_training = r'G:\\Shared drives\\TREEO BD Supply\\02. UGA\\01. TPPs\\03. Delight Ltd\\Due Diligence\\2024_07_24_Updated_Satellite_Assessment\\raw_data_shp_script\\00_input\\training_aoi_smaller.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we will select the map for eligibility_check_prospective_tpps\n",
      "layer of G:/Shared drives/TREEO BD Supply/satellite_verification/PPP/LPHD Belaban Rayak.shp is already added, check it on the map, save it in the same path if you edited\n"
     ]
    }
   ],
   "source": [
    "# empower the capability of arcpy, native arcgis scripting from a class made\n",
    "# Open the currently active project, you can also refer to actual project path, comment here below, and activate after\n",
    "project_path = \"CURRENT\"\n",
    "# project_path = r'G:\\My Drive\\TreeO_WORKS\\GIS_data\\ArcGIS_Pro\\TREEO\\TREEO.aprx'\n",
    "arc_ops= ArcpyOps(project_path_arcgis = project_path, map_name_arcgis= map_name_arcgis_pro)\n",
    "map = arc_ops.map\n",
    "# layer_aoi = arc_ops.selecting_layer(name_layer = aoi_layer_name_in_map_arcgis)\n",
    "AOIt_shp = arc_ops.select_adding_layer(config['AOI_path'])['layer_path']\n",
    "AOI = geemap.shp_to_ee(AOIt_shp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.path.normpath(config['AOI_path']) not in arc_ops.list_source_layers_in_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer of G:/Shared drives/TREEO BD Supply/satellite_verification/PPP/LPHD Belaban Rayak.shp is already added, check it on the map, save it in the same path if you edited\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FID</th>\n",
       "      <th>Shape</th>\n",
       "      <th>FID_1</th>\n",
       "      <th>kode_prov</th>\n",
       "      <th>kode_kab</th>\n",
       "      <th>hd_id</th>\n",
       "      <th>nama_kec</th>\n",
       "      <th>nama_desa</th>\n",
       "      <th>nama_ld</th>\n",
       "      <th>no_sk_pphd</th>\n",
       "      <th>tgl_sk_pph</th>\n",
       "      <th>no_sk_pak_</th>\n",
       "      <th>tgl_sk_pak</th>\n",
       "      <th>luas_hl</th>\n",
       "      <th>luas_hpt</th>\n",
       "      <th>luas_hp</th>\n",
       "      <th>luas_hpk</th>\n",
       "      <th>luas_pphd</th>\n",
       "      <th>st_area_sh</th>\n",
       "      <th>st_length_</th>\n",
       "      <th>A1NAME</th>\n",
       "      <th>A1CODE</th>\n",
       "      <th>A2CODE</th>\n",
       "      <th>A2NAME</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>A2TEXT</th>\n",
       "      <th>Hectares</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>(12296692.253643373, -200833.35952928432)</td>\n",
       "      <td>554.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>6104.0</td>\n",
       "      <td>610418.0</td>\n",
       "      <td>Sungai Melayu Rayak</td>\n",
       "      <td>Sungai Melayu</td>\n",
       "      <td>LPHD Belaban Rayak</td>\n",
       "      <td>SK.4670/MENLHK-PSKL/PKPS/PSL.0/7/2018</td>\n",
       "      <td>2018/07/06 08:00:00.000</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>3383.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3383.0</td>\n",
       "      <td>0.002752</td>\n",
       "      <td>0.229771</td>\n",
       "      <td>KALIMANTAN BARAT</td>\n",
       "      <td>61.0</td>\n",
       "      <td>6106.0</td>\n",
       "      <td>KETAPANG</td>\n",
       "      <td>Kabupaten</td>\n",
       "      <td>6106</td>\n",
       "      <td>3385.72723</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FID                                      Shape  FID_1  ...  A2TEXT    Hectares  id\n",
       "0    0  (12296692.253643373, -200833.35952928432)  554.0  ...    6106  3385.72723   0\n",
       "\n",
       "[1 rows x 28 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field 'id' found. Proceeding with operations masking based on AOI \n",
      "please continue\n"
     ]
    }
   ],
   "source": [
    "# lets print below the layer and convert into df if field names is exist\n",
    "# Get the layer's attribute table fields\n",
    "layer_aoi_arc = arc_ops.select_adding_layer(config['AOI_path'])['layer']\n",
    "fields = [field.name for field in arcpy.ListFields(layer_aoi_arc)]\n",
    "\n",
    "# Initialize an empty list to hold the data\n",
    "data = []\n",
    "\n",
    "# Use a SearchCursor to iterate over the rows in the attribute table\n",
    "with arcpy.da.SearchCursor(layer_aoi_arc, fields) as cursor:\n",
    "    for row in cursor:\n",
    "        data.append(row)\n",
    "\n",
    "# Create a pandas DataFrame from the data\n",
    "df = pd.DataFrame(data, columns=fields)\n",
    "display(df)\n",
    "\n",
    "#for area id in shapefile that identified the data, and will converted into raster\n",
    "OID = config['OID_field_name']  #IMPORTANT TO CHECK OID based on the column ID\n",
    "if OID not in fields:\n",
    "    print(f'field_name of {OID} is not exist ERROR WILL HAPPEN!!!!')\n",
    "    raise ValueError(f\"Field '{OID}' not found in the fields: {fields}\")\n",
    "else:\n",
    "    print(f\"Field '{OID}' found. Proceeding with operations masking based on AOI \\nplease continue\")\n",
    "    # Proceed with further operations, like converting to raster, etc.\n",
    "    #############################################\n",
    "    ##################################################################################\n",
    "    ### Masking and overlay and area helper Make an image out of the AOI area attribute -> convert featurecollection into raster (image) for overlaying tools\n",
    "    AOI_img = AOI.filter(ee.Filter.notNull([OID])).reduceToImage(\n",
    "        properties= [OID],\n",
    "        reducer= ee.Reducer.first()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validate the AOI input: \n",
      "trying to list the featurecollection\n",
      "now for loop to feature size range\n",
      "All features have a valid \"id\" column with integer values.\n",
      "layer of G:/Shared drives/TREEO BD Supply/satellite_verification/PPP/traning_point_merged_belaban.shp is already added, check it on the map, save it in the same path if you edited\n",
      "validate input training points\n",
      "before_validation:  (200, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FID</th>\n",
       "      <th>Shape</th>\n",
       "      <th>id</th>\n",
       "      <th>cd</th>\n",
       "      <th>code_lu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>(12298837.387797227, -200304.00237333647)</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>(12293945.341936655, -202216.47258877862)</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>(12297955.557603471, -200834.47418906735)</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>(12296728.038661005, -202186.20629604792)</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>(12295262.999174526, -199212.03719895022)</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>195</td>\n",
       "      <td>(12299589.276132282, -202026.49348096154)</td>\n",
       "      <td>195</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>196</td>\n",
       "      <td>(12294414.127457334, -198748.18544829503)</td>\n",
       "      <td>196</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>197</td>\n",
       "      <td>(12295901.055777473, -202159.81213440988)</td>\n",
       "      <td>197</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>198</td>\n",
       "      <td>(12296042.34700979, -201160.85203447298)</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>199</td>\n",
       "      <td>(12296612.18516571, -201918.61732885212)</td>\n",
       "      <td>199</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FID                                      Shape   id  cd  code_lu\n",
       "0      0  (12298837.387797227, -200304.00237333647)    0   3        3\n",
       "1      1  (12293945.341936655, -202216.47258877862)    1   4        4\n",
       "2      2  (12297955.557603471, -200834.47418906735)    2   1        1\n",
       "3      3  (12296728.038661005, -202186.20629604792)    3   1        1\n",
       "4      4  (12295262.999174526, -199212.03719895022)    4   1        1\n",
       "..   ...                                        ...  ...  ..      ...\n",
       "195  195  (12299589.276132282, -202026.49348096154)  195   4        4\n",
       "196  196  (12294414.127457334, -198748.18544829503)  196   3        3\n",
       "197  197  (12295901.055777473, -202159.81213440988)  197   1        1\n",
       "198  198   (12296042.34700979, -201160.85203447298)  198   1        1\n",
       "199  199   (12296612.18516571, -201918.61732885212)  199   1        1\n",
       "\n",
       "[200 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after validation:  (200, 5)\n"
     ]
    }
   ],
   "source": [
    "from osi.arcpy.utils import safe_get_data_source\n",
    "\n",
    "# smarter way to check\n",
    "print('validate the AOI input: ')\n",
    "validate_aoi(AOI, ee, config['OID_field_name'])\n",
    "\n",
    "arc_ops.list_layers = map.listLayers()\n",
    "arc_ops.list_source_layers_in_map = [safe_get_data_source(layer) for layer in arc_ops.list_layers]\n",
    "input_training = arc_ops.select_adding_layer(config['input_training'])['layer_path']\n",
    "input_training_ee = geemap.shp_to_ee(config['input_training'])\n",
    "\n",
    "print('validate input training points')\n",
    "fields_input_training = [field.name for field in arcpy.ListFields(input_training)]\n",
    "\n",
    "# Initialize an empty list to hold the data\n",
    "data_input_training = []\n",
    "\n",
    "# Use a SearchCursor to iterate over the rows in the attribute table\n",
    "with arcpy.da.SearchCursor(input_training, fields_input_training) as cursor:\n",
    "    for row in cursor:\n",
    "        data_input_training.append(row)\n",
    "\n",
    "# Create a pandas DataFrame from the data\n",
    "df = pd.DataFrame(data_input_training, columns=fields_input_training)\n",
    "print('before_validation: ',df.shape)\n",
    "# Function to check if a value is an integer\n",
    "def is_integer(value):\n",
    "    return isinstance(value, int)\n",
    "\n",
    "# Filter out non-integer values in the 'code_lu' column\n",
    "df['code_lu'] = df['code_lu'].apply(lambda x: x if is_integer(x) else None)\n",
    "display(df)\n",
    "print('after validation: ',df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [f.name for f in map.listLayers()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [f.name for f in arc_ops.list_layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now starting to do analysis\n",
    "# initiate instance class for the image collection and later mosaicking\n",
    "classInputCollection = ImageCollection(I_satellite=I_satellite,\n",
    "                                       AOI=AOI, \n",
    "                                       date_start_end=config['date_start_end'], \n",
    "                                       cloud_cover_threshold = config['cloud_cover_threshold'],\n",
    "                                       region=config['region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selecting Planet images\n"
     ]
    }
   ],
   "source": [
    "# run the method from image collection loaded, cloudless compositing until to image_mosaick\n",
    "image_mosaick = classInputCollection.image_mosaick()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://earthengine.googleapis.com/v1/projects/ee-iwansetiawan/maps/8ed176a8d683fdd7938384e73606c7ea-2c5be473ed8cf3bc8f84ced8c40943b2/tiles/{z}/{x}/{y}\n",
      "removing and re-adding the layer name: Planet mosaicked - 2024-5-1-2024-5-31 VegColor\n",
      "layer re-added: Planet mosaicked - 2024-5-1-2024-5-31 VegColor\n"
     ]
    }
   ],
   "source": [
    "arc_ops.list_layers = map.listLayers()\n",
    "arc_ops.list_source_layers_in_map = [safe_get_data_source(layer) for layer in arc_ops.list_layers]\n",
    "\n",
    "vis_params_image_mosaick = {\"bands\":[\"red\",\"green\",\"blue\"],\"min\":0,\"max\":0.1,\"gamma\":1}\n",
    "layer_name_image_mosaick = f'image_mosaick_result_ee_{config[\"project_name\"]}'\n",
    "# image_mosaick_arcgis_layer = arc_ops.adding_ee_to_arcgisPro(image_mosaick, vis_params_image_mosaick,\n",
    "#                                                    layer_name_image_mosaick)\n",
    "image_mosaick_arcgis_layer = None\n",
    "\n",
    "if config['I_satellite'] == 'Planet':\n",
    "    # true color {\"bands\":[\"red\",\"green\",\"blue\"],\"min\":0,\"max\":0.6,\"gamma\":1.5}\n",
    "    # nir veg color {\"bands\":[\"red\",\"nir\",\"blue\"],\"min\":0,\"max\":0.6,\"gamma\":1.5 }\n",
    "    image_mosaick_arcgis_layer = arc_ops.adding_ee_to_arcgisPro(image_mosaick,{\"bands\":[\"red\",\"green\",\"blue\"],\"min\":0,\"max\":0.6,\"gamma\":1.5}, f'{I_satellite} mosaicked - {start_date}-{end_date} VegColor')\n",
    "else:\n",
    "    image_mosaick_arcgis_layer = arc_ops.adding_ee_to_arcgisPro(image_mosaick,{'bands': ['swir2', 'nir', 'red'], 'min': 0, 'max': 0.6, 'gamma': 1.5 }, f'{I_satellite} mosaicked - {start_date}-{end_date}')\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selecting Planet images\n",
      "selecting Planet images\n",
      "processing AVI\n",
      "processing BSI\n",
      "processing SI\n",
      "Normalizing to 100 AVI\n",
      "Normalizing to 100 AVI\n",
      "Normalizing to 100 BSI\n",
      "Normalizing to 100 SI\n",
      "Combining AVI AND BSI\n",
      "no thermal band, choosing Planet images\n",
      "Processing means center of AVI_BSI please wait\n",
      "Now we proceed to the PCA of Vegetation density\n",
      "Success get the PCA normalized of VD => SVI\n",
      "Now calculating the FCD from SVI and SSI - selecting band svi1 svi2 ssi1 and ssi2\n",
      "finish processing PCA, the result: FCD1_1 and FCD2_1 please continue\n",
      "https://earthengine.googleapis.com/v1/projects/ee-iwansetiawan/maps/7a564a70d7a3a696cf1de6d9e9c6b1e2-99dde17dcaf0524e9743b53ff14620e5/tiles/{z}/{x}/{y}\n",
      "removing and re-adding the layer name: FCD1_1_belaban_rayak\n",
      "layer re-added: FCD1_1_belaban_rayak\n",
      "https://earthengine.googleapis.com/v1/projects/ee-iwansetiawan/maps/a0e6ade221f2cad3d436812ebbd5482b-c71e6409a562cabce89acde3308aa3fe/tiles/{z}/{x}/{y}\n",
      "removing and re-adding the layer name: FCD2_1_belaban_rayak\n",
      "layer re-added: FCD2_1_belaban_rayak\n",
      "finish processing PCA please continue\n"
     ]
    }
   ],
   "source": [
    "arc_ops.list_layers = map.listLayers()\n",
    "arc_ops.list_source_layers_in_map = [safe_get_data_source(layer) for layer in arc_ops.list_layers]\n",
    "\n",
    "classImageSpectral = SpectralAnalysis(image_mosaick,config)\n",
    "class_FCD_run = FCDCalc(config).fcd_calc()\n",
    "FCD1_1 = class_FCD_run['FCD1_1']\n",
    "FCD2_1 = class_FCD_run['FCD2_1']\n",
    "\n",
    "FCD1_1_arcgis_layer = arc_ops.adding_ee_to_arcgisPro(FCD1_1, {'min':0 ,'max':80, 'palette':['ff4c16', 'ffd96c', '39a71d']},\n",
    "                                                   f'FCD1_1_{project_name}')\n",
    "\n",
    "FCD2_1_arcgis_layer = arc_ops.adding_ee_to_arcgisPro(FCD2_1, {'min':0 ,'max':80, 'palette':['ff4c16', 'ffd96c', '39a71d']},\n",
    "                                                   f'FCD2_1_{project_name}')\n",
    "\n",
    "print('finish processing PCA please continue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now this is historical data to overlay later with current baseline (landcover)\n",
    "hansen_class = HansenHistorical(config)\n",
    "run_hansen = hansen_class.initiate_tcl()\n",
    "LastImageLandsat, treeLossYear, minLoss, ForestArea2000Hansen, gfc =  \\\n",
    "                                 run_hansen['LastImageLandsat'], \\\n",
    "                                 run_hansen['treeLossYear'], \\\n",
    "                                 run_hansen['minLoss'], \\\n",
    "                                 run_hansen['ForestArea2000Hansen'], \\\n",
    "                                 run_hansen['gfc']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding the map of Forest, FCD >= 45% and mask only if not water in area (hansen) and NDWI\n",
      "Adding the map of Shrubland, FCD <  45% and FCD >= 45%\n",
      "Adding the map of Grassland or Openland, FCD  < 45%\n",
      "Processing - the zoning classification\n",
      "finish processing, merging all the zone into one image\n",
      "https://earthengine.googleapis.com/v1/projects/ee-iwansetiawan/maps/a089b991bc97d5dbec96efce49584e4e-5098d0fafec03b8a0ba2b76ddb63694c/tiles/{z}/{x}/{y}\n",
      "removing and re-adding the layer name: FCD_classified_zone_belaban_rayak\n",
      "layer re-added: FCD_classified_zone_belaban_rayak\n"
     ]
    }
   ],
   "source": [
    "arc_ops.list_layers = map.listLayers()\n",
    "arc_ops.list_source_layers_in_map = [safe_get_data_source(layer) for layer in arc_ops.list_layers]\n",
    "\n",
    "config['AOI_img'] = AOI_img\n",
    "\n",
    "class_assigning_fcd =  AssignClassZone(config, FCD1_1=FCD1_1, FCD2_1=FCD2_1)\n",
    "list_images_classified = class_assigning_fcd.assigning_fcd_class(gfc, minLoss)\n",
    "\n",
    "fcd_classified_zone = list_images_classified['all_zone']\n",
    "\n",
    "vis_params_fcd_classified = class_assigning_fcd.vis_param_merged\n",
    "# Convert the dictionary to the LEGEND_ITEMS format\n",
    "legend_items = convert_to_legend_items(class_assigning_fcd.legend_class)\n",
    "\n",
    "fcd_classified_zone_arcgis_layer = arc_ops.adding_ee_to_arcgisPro(fcd_classified_zone, vis_params_fcd_classified,\n",
    "                                                   f'FCD_classified_zone_{project_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ADDING DIRECTLY SPECTRAL INDICES\n",
    "# classImageSpectral\n",
    "pca_scale = classImageSpectral.pca_scale #pca_scale is spatial resolution. eg planet: 5\n",
    "ndwi_image = classImageSpectral.NDWI_func()\n",
    "msavi2_image = classImageSpectral.MSAVI2_func()\n",
    "mtvi2_image = classImageSpectral.MTVI2_func()\n",
    "ndvi_image = classImageSpectral.NDVI_func()\n",
    "vari_image = classImageSpectral.VARI_func()\n",
    "\n",
    "image_mosaick_ndvi_ndwi_msavi2_mtvi2_vari = (\n",
    "    image_mosaick\n",
    "    .addBands(ndwi_image)\n",
    "    .addBands(msavi2_image)\n",
    "    .addBands(mtvi2_image)\n",
    "    .addBands(ndvi_image)\n",
    "    .addBands(vari_image)\n",
    ")\n",
    "\n",
    "red_norm = normalization_100(image_mosaick_ndvi_ndwi_msavi2_mtvi2_vari.select(['red']), pca_scale=pca_scale, AOI=AOI)\n",
    "green_norm = normalization_100(image_mosaick_ndvi_ndwi_msavi2_mtvi2_vari.select(['green']), pca_scale=pca_scale, AOI=AOI)\n",
    "blue_norm = normalization_100(image_mosaick_ndvi_ndwi_msavi2_mtvi2_vari.select(['blue']), pca_scale=pca_scale, AOI=AOI)\n",
    "nir_norm = normalization_100(image_mosaick_ndvi_ndwi_msavi2_mtvi2_vari.select(['nir']), pca_scale=pca_scale, AOI=AOI)\n",
    "\n",
    "image_norm = red_norm.addBands(green_norm).addBands(blue_norm).addBands(nir_norm)\n",
    "\n",
    "image_norm_ndvi = normalization_100(image_mosaick_ndvi_ndwi_msavi2_mtvi2_vari.select('NDVI'), pca_scale=pca_scale, AOI=AOI)\n",
    "image_norm_ndwi = normalization_100(image_mosaick_ndvi_ndwi_msavi2_mtvi2_vari.select('ndwi'), pca_scale=pca_scale, AOI=AOI)\n",
    "image_norm_msavi2 = normalization_100(image_mosaick_ndvi_ndwi_msavi2_mtvi2_vari.select('msavi2'), pca_scale=pca_scale, AOI=AOI)\n",
    "image_norm_mtvi2 = normalization_100(image_mosaick_ndvi_ndwi_msavi2_mtvi2_vari.select('MTVI2'), pca_scale=pca_scale, AOI=AOI)\n",
    "image_norm_vari = normalization_100(image_mosaick_ndvi_ndwi_msavi2_mtvi2_vari.select('VARI'), pca_scale=pca_scale, AOI=AOI)\n",
    "\n",
    "# red_norm.bandNames().getInfo()\n",
    "image_norm_with_spectral_indices = image_norm.addBands(image_norm_ndvi).addBands(image_norm_ndwi).addBands(image_norm_msavi2).addBands(image_norm_mtvi2).addBands(image_norm_vari)\n",
    "image_norm_with_spectral_indices_FCD = image_norm_with_spectral_indices.addBands(FCD2_1.select('FCD').rename('FCD2_1')).addBands(FCD1_1.select('FCD').rename('FCD1_1'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snic list bands: ['red_mean', 'green_mean', 'blue_mean', 'nir_mean', 'ndwi_mean', 'msavi2_mean', 'MTVI2_mean', 'NDVI_mean', 'VARI_mean', 'FCD1_1_mean', 'FCD2_1_mean', 'area', 'clusters_min', 'width', 'height']\n"
     ]
    }
   ],
   "source": [
    "obia = OBIASegmentation(config=config, image=image_norm_with_spectral_indices_FCD, pca_scale=pca_scale) #pca_scale basically is spatial resolution e.g planet: 5\n",
    "clusters = obia.SNIC_cluster()['clusters']\n",
    "object_properties_image = obia.summarize_cluster(is_include_std = False)\n",
    "\n",
    "lc = LandcoverML(config=config,\n",
    "                 input_image = image_norm_with_spectral_indices_FCD,\n",
    "                cluster_properties=object_properties_image,\n",
    "                pca_scale = pca_scale)\n",
    "\n",
    "classifier = lc.run_classifier()\n",
    "\n",
    "legend_lc = lc.lc_legend_param()\n",
    "vis_param_lc = legend_lc['vis_param_lc']\n",
    "\n",
    "legend_lc = legend_lc['legend_class']\n",
    "# Convert the dictionary to the LEGEND_ITEMS format\n",
    "legend_items_lc = convert_to_legend_items(legend_lc)\n",
    "\n",
    "training_points = classifier['training_points']\n",
    "validation_points = classifier['validation_points']\n",
    "\n",
    "rf = classifier['classified_image_rf']\n",
    "svm = classifier['classified_image_svm']\n",
    "gbm = classifier['classified_image_gbm']\n",
    "cart = classifier['classified_image_cart']\n",
    "\n",
    "# fcd lc, 5 classes only, just nice to know\n",
    "fcd_lc = list_images_classified['fcd_class_lc_image']\n",
    "fcd_lc_vs = list_images_classified['vis_param_segment_lc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# legend lc\n",
    "legend_class_lc = LegendsBuilder(legend_items=legend_items_lc)\n",
    "legend_class_lc.create_legend('landcover')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# legend zone\n",
    "legend_class_zone = LegendsBuilder(legend_items=legend_items)\n",
    "legend_class_zone.create_legend('final-zone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom color spectrum - override example\n",
    "legend_class_lc.create_colorbar('Forest Canopy Density',{'min': 0, 'max': 100, 'palette': ['#ff4c16', '#ffd96c', '#39a71d']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_mosaick_all_bands = image_mosaick.addBands([FCD2_1.select('FCD').rename('FCD2_1'), FCD1_1.select('FCD').rename('FCD1_1')])\n",
    "\n",
    "## ADDING DIRECTLY SPECTRAL INDICES\n",
    "# classImageSpectral\n",
    "pca_scale = classImageSpectral.pca_scale\n",
    "ndwi_image = classImageSpectral.NDWI_func()\n",
    "msavi2_image = classImageSpectral.MSAVI2_func()\n",
    "mtvi2_image = classImageSpectral.MTVI2_func()\n",
    "ndvi_image = classImageSpectral.NDVI_func()\n",
    "vari_image = classImageSpectral.VARI_func()\n",
    "\n",
    "image_mosaick_ndvi_ndwi_msavi2_mtvi2_vari = (\n",
    "    image_mosaick_all_bands\n",
    "    .addBands(ndwi_image)\n",
    "    .addBands(msavi2_image)\n",
    "    .addBands(mtvi2_image)\n",
    "    .addBands(ndvi_image)\n",
    "    .addBands(vari_image)\n",
    ")\n",
    "\n",
    "red_norm = normalization_100(image_mosaick.select(['red']), pca_scale=pca_scale, AOI=AOI)\n",
    "green_norm = normalization_100(image_mosaick.select(['green']), pca_scale=pca_scale, AOI=AOI)\n",
    "blue_norm = normalization_100(image_mosaick.select(['blue']), pca_scale=pca_scale, AOI=AOI)\n",
    "nir_norm = normalization_100(image_mosaick.select(['nir']), pca_scale=pca_scale, AOI=AOI)\n",
    "\n",
    "image_norm = red_norm.addBands(green_norm).addBands(blue_norm).addBands(nir_norm)\n",
    "\n",
    "image_norm_ndvi = normalization_100(image_mosaick_ndvi_ndwi_msavi2_mtvi2_vari.select('NDVI'), pca_scale=pca_scale, AOI=AOI)\n",
    "image_norm_ndwi = normalization_100(image_mosaick_ndvi_ndwi_msavi2_mtvi2_vari.select('ndwi'), pca_scale=pca_scale, AOI=AOI)\n",
    "image_norm_msavi2 = normalization_100(image_mosaick_ndvi_ndwi_msavi2_mtvi2_vari.select('msavi2'), pca_scale=pca_scale, AOI=AOI)\n",
    "image_norm_mtvi2 = normalization_100(image_mosaick_ndvi_ndwi_msavi2_mtvi2_vari.select('MTVI2'), pca_scale=pca_scale, AOI=AOI)\n",
    "image_norm_vari = normalization_100(image_mosaick_ndvi_ndwi_msavi2_mtvi2_vari.select('VARI'), pca_scale=pca_scale, AOI=AOI)\n",
    "\n",
    "# red_norm.bandNames().getInfo()\n",
    "image_norm_with_spectral_indices = image_norm.addBands(image_norm_ndvi).addBands(image_norm_ndwi).addBands(image_norm_msavi2).addBands(image_norm_mtvi2).addBands(image_norm_vari)\n",
    "image_norm_with_spectral_indices_FCD = image_norm_with_spectral_indices.addBands(FCD2_1.select('FCD').rename('FCD2_1')).addBands(FCD1_1.select('FCD').rename('FCD1_1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snic list bands: ['red_mean', 'green_mean', 'blue_mean', 'nir_mean', 'ndwi_mean', 'msavi2_mean', 'MTVI2_mean', 'NDVI_mean', 'VARI_mean', 'FCD1_1_mean', 'FCD2_1_mean', 'area', 'clusters_min', 'width', 'height']\n"
     ]
    }
   ],
   "source": [
    "obia = OBIASegmentation(config=config, image=image_norm_with_spectral_indices_FCD, pca_scale=pca_scale) #pca_scale basically is spatial resolution e.g planet: 5\n",
    "clusters = obia.SNIC_cluster()['clusters']\n",
    "object_properties_image = obia.summarize_cluster(is_include_std = False)\n",
    "\n",
    "lc = LandcoverML(config=config,\n",
    "                 input_image = image_norm_with_spectral_indices_FCD,\n",
    "                cluster_properties=object_properties_image,\n",
    "                 num_class=5, # make sure this one is align with total type landcover stratification, for a sample creation\n",
    "                pca_scale = pca_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we will use the existing training_points or labelled\n",
      "location of the training sample is in G:/Shared drives/TREEO BD Supply/satellite_verification/PPP/traning_point_merged_belaban.shp\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#create stratified random sampling based on K-means classes\n",
    "# create_training_gee\n",
    "if create_training_gee:\n",
    "    print('yes')\n",
    "    \n",
    "    ########### SAMPLE NUMBER CREATION BASED ON https://docs.google.com/spreadsheets/d/1J8MEi4IDn6faok6UUn9L64T61yWk0D4q/edit?gid=1919918133#gid=1919918133\n",
    "#     # example\n",
    "#     strata_area_based_kmeans = {\n",
    "#     'Forest': 100,\n",
    "#     'Shrub': 100,\n",
    "#     'Grass': 100,\n",
    "#     'Crop': 100,\n",
    "#     'Water': 100\n",
    "#     }\n",
    "    \n",
    "    # try with K-means input\n",
    "    random_samples_creation = lc.stratified_random_creation()\n",
    "    df_sample_n = random_samples_creation['df_sample_n']\n",
    "    stratified_training = random_samples_creation['stratified_training']\n",
    "       \n",
    "    # Export the samples to a CSV file in Google Drive\n",
    "    export_stratified_point = ee.batch.Export.table.toDrive(\n",
    "        collection=stratified_training,\n",
    "        description=f'Stratified_Random_Samples_{project_name}',\n",
    "        folder=f'lu_input_{project_name}',\n",
    "        fileFormat='SHP'\n",
    "    )\n",
    "\n",
    "    # Start the export task\n",
    "    export_stratified_point.start()\n",
    "\n",
    "    # Monitor the task status\n",
    "    import time\n",
    "    while export_stratified_point.active():\n",
    "        print('Export task status:', export_stratified_point.status())\n",
    "        time.sleep(10)\n",
    "\n",
    "    print(f'Export task completed: Stratified_Random_Samples_{project_name}')\n",
    "    \n",
    "    # Open in gdrive in your computer\n",
    "    location_stratified_exported = fr'G:\\My Drive\\lu_input_{project_name}\\Stratified_Random_Samples_{project_name}.shp'\n",
    "    print(location_stratified_exported) #make sure the location is correct (G: is connected by gdrive desktop!)\n",
    "    \n",
    "    # arcgis layer object\n",
    "    training_points = map.addDataFromPath(location_stratified_exported)\n",
    "    # training_points.name = 'change the name here'\n",
    "    \n",
    "    path_shp_input_training = training_points.dataSource\n",
    "    \n",
    "else:\n",
    "    print('we will use the existing training_points or labelled')\n",
    "    print(f'location of the training sample is in {config[\"input_training\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://earthengine.googleapis.com/v1/projects/ee-iwansetiawan/maps/086ac8a788b3713264ab53c2a0139cd6-bad2f6bd01d088730a9b8a7b037f055c/tiles/{z}/{x}/{y}\n",
      "removing and re-adding the layer name: fcd-method_lc_result\n",
      "layer re-added: fcd-method_lc_result\n",
      "https://earthengine.googleapis.com/v1/projects/ee-iwansetiawan/maps/1e33547b76b3388aceb2ec0ee90ae5d4-82e4c5eb346e12e51a5a225e54ed759a/tiles/{z}/{x}/{y}\n",
      "removing and re-adding the layer name: Random_forest_lc_result\n",
      "layer re-added: Random_forest_lc_result\n",
      "https://earthengine.googleapis.com/v1/projects/ee-iwansetiawan/maps/d6fd8f911fd16cf4342c7f27baf25b1b-8199777c222698c3bfd89d81f89ea0c8/tiles/{z}/{x}/{y}\n",
      "removing and re-adding the layer name: SVM_lc_result\n",
      "layer re-added: SVM_lc_result\n",
      "https://earthengine.googleapis.com/v1/projects/ee-iwansetiawan/maps/ac28379918a9e9bfb40c0b233cf76b45-2cf50b12beb627b76526d2364fb284cb/tiles/{z}/{x}/{y}\n",
      "removing and re-adding the layer name: GBM_lc_result\n",
      "layer re-added: GBM_lc_result\n",
      "https://earthengine.googleapis.com/v1/projects/ee-iwansetiawan/maps/1b9271c79bb124e0195d08dfb862707c-3215bfb19bb58e1a7f3f2b9a32723212/tiles/{z}/{x}/{y}\n",
      "removing and re-adding the layer name: CART_lc_result\n",
      "layer re-added: CART_lc_result\n"
     ]
    }
   ],
   "source": [
    "arc_ops.list_layers = map.listLayers()\n",
    "arc_ops.list_source_layers_in_map = [safe_get_data_source(layer) for layer in arc_ops.list_layers]\n",
    "\n",
    "# starting to do ML analysis\n",
    "classifier = lc.run_classifier()\n",
    "\n",
    "legend_lc = lc.lc_legend_param()\n",
    "vis_param_lc = legend_lc['vis_param_lc']\n",
    "\n",
    "training_points = classifier['training_points']\n",
    "validation_points = classifier['validation_points']\n",
    "\n",
    "rf = classifier['classified_image_rf']\n",
    "svm = classifier['classified_image_svm']\n",
    "gbm = classifier['classified_image_gbm']\n",
    "cart = classifier['classified_image_cart']\n",
    "\n",
    "# fcd lc, 5 classes only, just nice to know\n",
    "fcd_lc = list_images_classified['fcd_class_lc_image']\n",
    "fcd_lc_vs = list_images_classified['vis_param_segment_lc']\n",
    "\n",
    "fcd_lc_arc = arc_ops.adding_ee_to_arcgisPro(fcd_lc,fcd_lc_vs, 'fcd-method_lc_result')\n",
    "rf_arc = arc_ops.adding_ee_to_arcgisPro(rf,vis_param_lc,'Random_forest_lc_result')\n",
    "svm_arc = arc_ops.adding_ee_to_arcgisPro(svm,vis_param_lc,'SVM_lc_result')\n",
    "gbm_arc = arc_ops.adding_ee_to_arcgisPro(gbm,vis_param_lc,'GBM_lc_result')\n",
    "cart_arc = arc_ops.adding_ee_to_arcgisPro(cart,vis_param_lc,'CART_lc_result')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------\n",
      "Algorithm of ML used: fcd\n",
      "Confusion Matrix:\n",
      "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 19, 0, 2, 0, 0, 0, 0, 0, 0], [0, 5, 0, 3, 0, 0, 0, 0, 0, 0], [0, 1, 0, 12, 11, 0, 0, 0, 0, 0], [0, 0, 0, 1, 8, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 4, 0, 0, 0, 0, 0]]\n",
      "Overall Accuracy: 0.582089552238806\n",
      "Producer's Accuracy: [[0], [0.9047619047619048], [0], [0.5], [0.8888888888888888], [0], [0], [0], [0], [0]]\n",
      "User's Accuracy: [[0, 0.76, 0, 0.631578947368421, 0.34782608695652173, 0, 0, 0, 0, 0]]\n",
      "Kappa: 0.4316873674644047\n",
      "-------------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------------\n",
      "Algorithm of ML used: rf\n",
      "Confusion Matrix:\n",
      "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 18, 3, 0, 0, 0, 0, 0, 0, 0], [0, 0, 8, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 21, 2, 0, 0, 0, 0, 0], [0, 0, 0, 2, 2, 0, 0, 0, 0, 5], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 2, 0, 0, 0, 0, 0, 3]]\n",
      "Overall Accuracy: 0.7761194029850746\n",
      "Producer's Accuracy: [[0], [0.8571428571428571], [1], [0.875], [0.2222222222222222], [0], [0], [0], [0], [0.6]]\n",
      "User's Accuracy: [[0, 1, 0.6666666666666666, 0.84, 0.5, 0, 0, 0, 0, 0.375]]\n",
      "Kappa: 0.6990116801437557\n",
      "-------------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------------\n",
      "Algorithm of ML used: svm\n",
      "Confusion Matrix:\n",
      "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 18, 2, 1, 0, 0, 0, 0, 0, 0], [0, 1, 7, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 21, 2, 0, 0, 0, 0, 1], [0, 0, 0, 2, 3, 0, 0, 0, 0, 4], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 4]]\n",
      "Overall Accuracy: 0.7910447761194029\n",
      "Producer's Accuracy: [[0], [0.8571428571428571], [0.875], [0.875], [0.3333333333333333], [0], [0], [0], [0], [0.8]]\n",
      "User's Accuracy: [[0, 0.9473684210526315, 0.7777777777777778, 0.875, 0.5, 0, 0, 0, 0, 0.4444444444444444]]\n",
      "Kappa: 0.719413700269219\n",
      "-------------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------------\n",
      "Algorithm of ML used: gbm\n",
      "Confusion Matrix:\n",
      "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 18, 3, 0, 0, 0, 0, 0, 0, 0], [0, 0, 8, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 23, 0, 0, 0, 0, 0, 0], [0, 0, 0, 2, 2, 0, 0, 0, 0, 5], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 2, 1, 0, 0, 0, 0, 2]]\n",
      "Overall Accuracy: 0.7910447761194029\n",
      "Producer's Accuracy: [[0], [0.8571428571428571], [1], [0.9583333333333334], [0.2222222222222222], [0], [0], [0], [0], [0.4]]\n",
      "User's Accuracy: [[0, 1, 0.6666666666666666, 0.8518518518518519, 0.6666666666666666, 0, 0, 0, 0, 0.2857142857142857]]\n",
      "Kappa: 0.7161875945537063\n",
      "-------------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------------\n",
      "Algorithm of ML used: cart\n",
      "Confusion Matrix:\n",
      "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 16, 5, 0, 0, 0, 0, 0, 0, 0], [0, 0, 7, 1, 0, 0, 0, 0, 0, 0], [0, 0, 1, 20, 3, 0, 0, 0, 0, 0], [0, 0, 0, 2, 1, 0, 0, 0, 0, 6], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 3, 0, 0, 0, 0, 1]]\n",
      "Overall Accuracy: 0.6716417910447762\n",
      "Producer's Accuracy: [[0], [0.7619047619047619], [0.875], [0.8333333333333334], [0.1111111111111111], [0], [0], [0], [0], [0.2]]\n",
      "User's Accuracy: [[0, 1, 0.5384615384615384, 0.8333333333333334, 0.14285714285714285, 0, 0, 0, 0, 0.14285714285714285]]\n",
      "Kappa: 0.5632592592592593\n",
      "-------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "lc.matrix_confusion(fcd_lc,validation_points,'fcd')\n",
    "lc.matrix_confusion(rf, validation_points, 'rf')\n",
    "lc.matrix_confusion(svm, validation_points, 'svm')\n",
    "lc.matrix_confusion(gbm, validation_points, 'gbm')\n",
    "lc.matrix_confusion(cart, validation_points, 'cart')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algo_ml_selected:  gbm\n"
     ]
    }
   ],
   "source": [
    "algo_ml_selected = 'rf'\n",
    "selected_image_lc = rf\n",
    "if config['algo_ml_selected'] == 'rf':\n",
    "    algo_ml_selected = 'rf'\n",
    "    selected_image_lc = rf\n",
    "elif config['algo_ml_selected'] == 'svm':\n",
    "    algo_ml_selected = 'svm'\n",
    "    selected_image_lc = svm\n",
    "elif config['algo_ml_selected'] == 'gbm':\n",
    "    algo_ml_selected = 'gbm'\n",
    "    selected_image_lc = gbm\n",
    "elif config['algo_ml_selected'] == 'cart':\n",
    "    algo_ml_selected = 'cart'\n",
    "    selected_image_lc = cart\n",
    "print('algo_ml_selected: ',algo_ml_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://earthengine.googleapis.com/v1/projects/ee-iwansetiawan/maps/59da9d50ab3f36c576d2d606a18a2bb5-3eeb84a0e25a9d00c7d71c9fcb9456d3/tiles/{z}/{x}/{y}\n",
      "removing and re-adding the layer name: Final_zone_ML_gbm_Hansen\n",
      "layer re-added: Final_zone_ML_gbm_Hansen\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<arcpy._mp.Layer object at 0x000002ABB4EB0DD0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arc_ops.list_layers = map.listLayers()\n",
    "arc_ops.list_source_layers_in_map = [safe_get_data_source(layer) for layer in arc_ops.list_layers]\n",
    "\n",
    "\n",
    "# re-overlay the data for zoning from the selected method if they give the best metric, and when we check visually the land cover map make sense, also FCD approach is already there\n",
    "image_for_zone = selected_image_lc\n",
    "\n",
    "# comment this first, just check the LC above, then run the overlay zoning classification after\n",
    "HighForestDense = list_images_classified['HighForestDense']\n",
    "\n",
    "final_zone = class_assigning_fcd.assign_zone_ml(image_for_zone, minLoss,AOI_img, HighForestDense)\n",
    "arc_ops.adding_ee_to_arcgisPro(final_zone, vis_params_fcd_classified, f'Final_zone_ML_{algo_ml_selected}_Hansen')  # the naming probably will need to change, for some concistencies only so that you understand again later to read the codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://earthengine.googleapis.com/v1/projects/ee-iwansetiawan/maps/78115bb957f53640b2f986d7ab715f50-b24919169361a98c692e6488fa1d332f/tiles/{z}/{x}/{y}\n",
      "finished adding slope\n",
      "Unique values: [4562]\n",
      "Value-Color Map: {4562: '#c0057f'}\n",
      "{4562: 'Arenosols'}\n",
      "https://earthengine.googleapis.com/v1/projects/ee-iwansetiawan/maps/b28d31ec95b1e239ec2c01ba219ab298-050a980b0b27181aff13d890aacd53d6/tiles/{z}/{x}/{y}\n",
      "https://earthengine.googleapis.com/v1/projects/ee-iwansetiawan/maps/fe580dae03865a0d91bb2f78f94609f9-7d14788474dd8be0eb88c9d9b3bace79/tiles/{z}/{x}/{y}\n",
      "https://earthengine.googleapis.com/v1/projects/ee-iwansetiawan/maps/36f0d03c022379f5527f23f7d6ccefe7-469422a07e574442b7b8902b58094f41/tiles/{z}/{x}/{y}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<arcpy._mp.Layer object at 0x000002ABABE5E750>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arc_ops.list_layers = map.listLayers()\n",
    "arc_ops.list_source_layers_in_map = [safe_get_data_source(layer) for layer in arc_ops.list_layers]\n",
    "\n",
    "\n",
    "#additional data\n",
    "# Load DEM data (replace 'dataset' with your actual DEM dataset)\n",
    "DEM = ee.Image('USGS/SRTMGL1_003').clip(AOI)\n",
    "\n",
    "# Calculate slope in degrees\n",
    "slope = ee.Terrain.slope(DEM)\n",
    "\n",
    "# Convert slope to percentage\n",
    "slopePercentage = slope.expression('tan(b*0.01745) * 100', {'b': slope})\n",
    "\n",
    "# Define slope classification thresholds\n",
    "thresholds = [8, 15, 25, 40]  # Adjust these thresholds as needed\n",
    "\n",
    "# Classify slope into categories using conditional statements\n",
    "slopeClasses = slopePercentage \\\n",
    "    .lte(thresholds[0]).multiply(1) \\\n",
    "    .add(slopePercentage.gt(thresholds[0]).And(slopePercentage.lte(thresholds[1])).multiply(2)) \\\n",
    "    .add(slopePercentage.gt(thresholds[1]).And(slopePercentage.lte(thresholds[2])).multiply(3)) \\\n",
    "    .add(slopePercentage.gt(thresholds[2]).And(slopePercentage.lte(thresholds[3])).multiply(4)) \\\n",
    "    .add(slopePercentage.gt(thresholds[3]).multiply(5))\n",
    "\n",
    "# Display the classified slope image\n",
    "palette = ['lightgreen', 'yellow', 'orange', 'pink', 'red']  # Change green to lightgreen\n",
    "vis_params = {'min': 1, 'max': 5, 'palette': palette}\n",
    "# Map.addLayer(slopeClasses, vis_params, 'Slope Classes')\n",
    "arc_ops.adding_ee_to_arcgisPro(slopeClasses, vis_params, 'Slope Classes')  \n",
    "print('finished adding slope')\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "## SOIL Overlay FAO\n",
    "FAO_soil = ee.Image(\"users/muhammadiqbaltreeo/HWSD2_FAO\").clip(AOI)\n",
    "# Get the unique values from the image\n",
    "unique_values = FAO_soil.reduceRegion(\n",
    "    reducer=ee.Reducer.frequencyHistogram(),\n",
    "    geometry=AOI.geometry(),\n",
    "    scale=30\n",
    ").getInfo()\n",
    "\n",
    "unique_values = list(unique_values['b1'].keys())\n",
    "unique_values = [int(f) for f in unique_values]\n",
    "print('Unique values:', unique_values)\n",
    "\n",
    "import random\n",
    "\n",
    "# Generate random colors for each unique value\n",
    "def get_random_color():\n",
    "    return \"#{:06x}\".format(random.randint(0, 0xFFFFFF))\n",
    "\n",
    "\n",
    "value_color_map = {value: get_random_color() for value in unique_values}\n",
    "print('Value-Color Map:', value_color_map)\n",
    "\n",
    "# Create a color palette based on the unique values and their corresponding colors\n",
    "palette = [value_color_map[value] for value in unique_values]\n",
    "\n",
    "# Create a visualization dictionary\n",
    "visualization = {\n",
    "    'min': min(unique_values),\n",
    "    'max': max(unique_values),\n",
    "    'palette': palette\n",
    "}\n",
    "\n",
    "smu_table = ee.FeatureCollection(\"users/muhammadiqbaltreeo/HWSD2_SMU\")\n",
    "\n",
    "# Get the data as a Python dictionary\n",
    "filtered_smu_table = smu_table.filter(ee.Filter.inList('HWSD2_SMU_ID', unique_values))\n",
    "\n",
    "# Get the filtered data as a Python dictionary\n",
    "filtered_smu_data = filtered_smu_table.getInfo()\n",
    "\n",
    "# Extract the features from the dictionary\n",
    "features = filtered_smu_data['features']\n",
    "\n",
    "# Extract properties from each feature\n",
    "properties_list = [feature['properties'] for feature in features]\n",
    "\n",
    "# Convert the list of properties to a pandas DataFrame\n",
    "df_snum = pd.DataFrame(properties_list)\n",
    "\n",
    "# Display the DataFrame\n",
    "# display(df_snum)\n",
    "\n",
    "# Extract the 'name' and 'snum' columns and convert them to a dictionary\n",
    "name_snum_dict = df_snum.set_index('HWSD2_SMU_ID')['name'].to_dict()\n",
    "print(name_snum_dict)\n",
    "\n",
    "# Update the legend dictionary to use the format \"snum: name_soil\"\n",
    "legend_dict = {f\"{snum}: {name_snum_dict[snum]}\": value_color_map[snum] for snum in unique_values}\n",
    "\n",
    "# Map.add_legend(title=\"Soil Type (FAO) Legend\", legend_dict=legend_dict)\n",
    "\n",
    "# Map.addLayer(FAO_soil.clip(AOI),visualization,'FAO_soil')\n",
    "arc_ops.adding_ee_to_arcgisPro(FAO_soil.clip(AOI),visualization,'FAO_soil')\n",
    "\n",
    "# Map.addLayer(AOIsmaller.style(**style), {}, 'AOI Smaller')\n",
    "# Map.addLayer(training_points, {'color': 'yellow'},\n",
    "#     'Training data location')\n",
    "arc_ops.adding_ee_to_arcgisPro(training_points, {'color': 'yellow'},\n",
    "    'Training data location')\n",
    "\n",
    "# Map.addLayer(validation_points, {'color': 'red'},\n",
    "#     'Validation data location')\n",
    "\n",
    "arc_ops.adding_ee_to_arcgisPro(validation_points, {'color': 'red'},\n",
    "    'Validation data location')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### EXPORTING\n",
    "# Define the export task.\n",
    "task4 = ee.batch.Export.table.toDrive(\n",
    "    collection=training_points,\n",
    "    description=f'training_points_{project_name}',\n",
    "    driveFolder =f'result_lu_class_zone_{project_name}',\n",
    "    fileFormat='GeoJSON'\n",
    ")\n",
    "\n",
    "# Define the export task.\n",
    "task5 = ee.batch.Export.table.toDrive(\n",
    "    collection=validation_points,\n",
    "    description=f'validation_points_{project_name}',\n",
    "    driveFolder =f'result_lu_class_zone_{project_name}',\n",
    "    fileFormat='GeoJSON'\n",
    ")\n",
    "\n",
    "\n",
    "# Start the export task.\n",
    "task4.start()\n",
    "task5.start()\n",
    "\n",
    "selected_class_zone = image_for_zone.select('Class').reduceToVectors(\n",
    "    geometryType='polygon',\n",
    "    reducer=ee.Reducer.countEvery(),\n",
    "    scale=pca_scale,\n",
    "    maxPixels=1e10,\n",
    "    geometry=AOI  # Add geometry parameter\n",
    ")\n",
    "\n",
    "task_zone_result_export = ee.batch.Export.table(final_zone, f'zone_result_{project_name}_{algo_ml_selected}_{config[\"super_pixel_size\"]}_cluster', {\n",
    "  'driveFolder': f'result_lu_class_zone_{project_name}',\n",
    "  'fileFormat': 'KML'\n",
    "})\n",
    "\n",
    "task_zone_result_export.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://earthengine.googleapis.com/v1/projects/ee-iwansetiawan/maps/59da9d50ab3f36c576d2d606a18a2bb5-ae0b70256353dbff90d9cff22433e4dc/tiles/{z}/{x}/{y}\n",
      "removing and re-adding the layer name: Final_zone_ML_gbm_Hansen\n",
      "layer re-added: Final_zone_ML_gbm_Hansen\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<arcpy._mp.Layer object at 0x0000015751800BD0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from osi.spectral_indices.utils import assigning_band\n",
    "from osi.classifying.utils import add_classes, add_images, select_band_if_exists, unmasked_helper\n",
    "\n",
    "forest_masked = selected_image_lc.updateMask(selected_image_lc.select(['classification']).eq(1))\n",
    "shrub_masked = selected_image_lc.updateMask(selected_image_lc.select(['classification']).eq(2))\n",
    "grass_masked = selected_image_lc.updateMask(selected_image_lc.select(['classification']).eq(3))\n",
    "openland_masked = selected_image_lc.updateMask(selected_image_lc.select(['classification']).eq(4))\n",
    "water_masked = selected_image_lc.updateMask(selected_image_lc.select(['classification']).eq(5))\n",
    "plantation_masked = selected_image_lc.updateMask(selected_image_lc.select(['classification']).eq(6))\n",
    "infrastructure_masked = selected_image_lc.updateMask(selected_image_lc.select(['classification']).eq(7))\n",
    "oil_palm_masked = selected_image_lc.updateMask(selected_image_lc.select(['classification']).eq(8))\n",
    "cropland_masked = selected_image_lc.updateMask(selected_image_lc.select(['classification']).eq(9))\n",
    "paddy_irigated_masked = selected_image_lc.updateMask(selected_image_lc.select(['classification']).eq(14))# arc_ops.adding_ee_to_arcgisPro(infrastructure_masked.randomVisualizer(),{},'test')\n",
    "\n",
    "def unmasked_helper(image, AOI_img, AOI):\n",
    "    mask_image = image.mask()\n",
    "    mask_image_inverted = mask_image.Not()\n",
    "    unmasked_image = AOI_img.unmask().updateMask(mask_image_inverted).clip(AOI)\n",
    "    return unmasked_image\n",
    "\n",
    "#sub-forest considering the fcd threshold of high density forest, regardless the ML method\n",
    "# HighForestDense = FCD.mask(FCD.gte(high_forest).And(unmaskedWaterAOI))\n",
    "unmaskedHighForest = AOI_img.unmask().updateMask(HighForestDense.mask().Not()).clip(AOI)\n",
    "yrf_forest = forest_masked.And(unmaskedHighForest)\n",
    "high_forest_fix = HighForestDense.And(forest_masked)\n",
    "\n",
    "band_name_image = config['band_name_image']\n",
    "\n",
    "######### general go-zone\n",
    "## Starting to retrieve from 10 TCL unmask\n",
    "unmaskedLoss = unmasked_helper(minLoss, AOI_img, AOI)\n",
    "# Unmasked Forest - the result is all the area outside of forest_masked (Total all forest), and now in no forest\n",
    "# maskHiF = forest_masked.mask()\n",
    "# maskHiF_inverted = maskHiF.Not()\n",
    "# unmaskedHiF = AOI_img.unmask().updateMask(maskHiF_inverted).clip(AOI)\n",
    "unmaskedHiF = unmasked_helper(forest_masked, AOI_img, AOI)\n",
    "# unmasked water\n",
    "waterinAOI = water_masked\n",
    "unmaskedWaterAOI = unmasked_helper(water_masked, AOI_img, AOI)\n",
    "# unmasked grey infrastructure\n",
    "unmasked_infrastructure = unmasked_helper(infrastructure_masked, AOI_img, AOI)\n",
    "# unmasked oil palm\n",
    "unmasked_oilpalm = unmasked_helper(oil_palm_masked, AOI_img, AOI)\n",
    "\n",
    "goZone = unmaskedLoss.And(unmaskedHiF).And(unmaskedWaterAOI).And(unmasked_infrastructure).And(unmasked_oilpalm)\n",
    "goZone_edited = ee.Image(assigning_band(config['band_name_image'],999,goZone))\n",
    "\n",
    "# forest category and no 10 years rule\n",
    "highBaselineF = forest_masked.And(unmaskedLoss)\n",
    "highf_edited = ee.Image(assigning_band(config['band_name_image'],111,highBaselineF))\n",
    "\n",
    "####### Get the overlay information of HighBaseline and Tree Cover Loss (Hansen), e.g., Young Regenerating Forest\n",
    "HiForestAndLoss = AOI_img.And(forest_masked.And(minLoss)) #minLoss is the actual TCL without overlaying with Sentinel\n",
    "tenyrfl_edited = ee.Image(assigning_band(band_name_image,888,HiForestAndLoss))\n",
    "# arc_ops.adding_ee_to_arcgisPro(tenyrfl_edited.randomVisualizer(),{},'tenyrlfl_edited')\n",
    "\n",
    "# Create a helper mask indicating where the smaller areas maskhiFL, distinguish only the highbaseline and TCL (mask) and assign mask as 1\n",
    "# Unmask the bigger raster in the areas to get the pixel value for area 'outside' HiFL (High Baseline and Forest Loss)\n",
    "unmaskedHiFL = unmasked_helper(HiForestAndLoss, AOI_img, AOI)\n",
    "#outcome result for 10 years data only that is not overlay with high baseline (Forest) unmaskedHiFL is Area that is not Forest Sentinel############\n",
    "tenYearsRule = unmaskedHiFL.And(minLoss)\n",
    "tenyrule_edited = ee.Image(assigning_band(band_name_image,8,tenYearsRule))\n",
    "# arc_ops.adding_ee_to_arcgisPro(tenyrule_edited.randomVisualizer(),{},'tenyrule_edited')\n",
    "\n",
    "#re-acquired the same method for 10 years rule data (GFW or Hansen data (pixel 30m))\n",
    "#assigning to zones:\n",
    "## GO ZONE\n",
    "Shrubland_gozone = shrub_masked.And(goZone_edited).select(['pixel'])\n",
    "Shrubland_gozone = ee.Image(assigning_band(config['band_name_image'],1,Shrubland_gozone))\n",
    "\n",
    "Grassland_gozone = grass_masked.And(goZone_edited).select(['pixel'])\n",
    "Grassland_gozone = ee.Image(assigning_band(config['band_name_image'],2,Grassland_gozone))\n",
    "\n",
    "Openland_gozone = openland_masked.And(goZone_edited).select(['pixel'])\n",
    "Openland_gozone = ee.Image(assigning_band(config['band_name_image'],3,Openland_gozone))\n",
    "\n",
    "Openland_gozone = openland_masked.And(goZone_edited).select(['pixel'])\n",
    "Openland_gozone = ee.Image(assigning_band(config['band_name_image'],3,Openland_gozone))\n",
    "\n",
    "Cropland_Gozone = cropland_masked.And(goZone_edited).select(['pixel'])\n",
    "Cropland_Gozone = ee.Image(assigning_band(config['band_name_image'],13,Cropland_Gozone))\n",
    "\n",
    "Paddy_Gozone = paddy_irigated_masked.And(goZone_edited).select(['pixel'])\n",
    "Paddy_Gozone = ee.Image(assigning_band(config['band_name_image'],14,Paddy_Gozone))\n",
    "\n",
    "## NO GO additional\n",
    "Plantation_noGozone = plantation_masked.And(goZone_edited).select(['pixel'])\n",
    "Plantation_noGozone = ee.Image(assigning_band(config['band_name_image'],10,Plantation_noGozone))\n",
    "\n",
    "Infrastructure_noGozone = infrastructure_masked.And(goZone_edited).select(['pixel'])\n",
    "Infrastructure_noGozone = ee.Image(assigning_band(config['band_name_image'],11,Infrastructure_noGozone))\n",
    "\n",
    "Oilpalm_noGozone = oil_palm_masked.And(goZone_edited).select(['pixel'])\n",
    "Oilpalm_noGozone = ee.Image(assigning_band(config['band_name_image'],12,Oilpalm_noGozone))\n",
    "\n",
    "# highbaseline\n",
    "# HighForestDense = FCD.mask(FCD.gte(high_forest).And(unmaskedWaterAOI))\n",
    "HighForestDense_no10yrs = HighForestDense.And(highf_edited).select(['pixel'])\n",
    "HighForestDense_no10yrs = ee.Image(assigning_band(config['band_name_image'],4,HighForestDense_no10yrs))\n",
    "\n",
    "#YRFForestDense = FCD.mask(FCD.gte(yrf_forest).And(unmaskedWaterAOI).And(FCD.lt(high_forest)))\n",
    "YRFForestDense_no10yrs = yrf_forest.And(highf_edited).select(['pixel'])\n",
    "YRFForestDense_no10yrs = ee.Image(assigning_band(config['band_name_image'],5,YRFForestDense_no10yrs))\n",
    "##########################\n",
    "\n",
    "# high baseline regrowth\n",
    "HighForestDense_10yrs = HighForestDense.And(tenyrfl_edited).select(['pixel'])\n",
    "HighForestDense_10yrs = ee.Image(assigning_band(config['band_name_image'],6,HighForestDense_10yrs))\n",
    "\n",
    "YRFForestDense_10yrs = yrf_forest.And(tenyrfl_edited).select(['pixel'])\n",
    "YRFForestDense_10yrs = ee.Image(assigning_band(config['band_name_image'],7,YRFForestDense_10yrs))\n",
    "############################\n",
    "\n",
    "# 10 years rule, straight forward\n",
    "# tenyrule_edited = ee.Image(assigning_band(band_name_image,8,tenYearsRule)) #tenyears rule not pass - 8  # already hard-coded set in the previous function\n",
    "No_pass_historical_years_rule = tenyrule_edited.select([config['band_name_image']])\n",
    "\n",
    "# Filter the images based on the 'Class' band, and add them one by one on map canvas!!!!!!!!!!!!!!!!!!!! # just comment this Map.addLayer if you want not to display one by one\n",
    "openland_gozone = Openland_gozone.select([config['band_name_image']])\n",
    "# Map.addLayer(openland_gozone,{'palette': ['#F89696']},'Open land - Go Zone')\n",
    "\n",
    "grassland_gozone = Grassland_gozone.select([config['band_name_image']])\n",
    "# Map.addLayer(grassland_gozone,{'palette': ['#ffff33']},'Grass land - Go Zone')\n",
    "\n",
    "shrubland_gozone = Shrubland_gozone.select([config['band_name_image']])\n",
    "# Map.addLayer(shrubland_gozone,{'palette': ['#ffe3b3']},'Shrub land - Go Zone')\n",
    "\n",
    "yrf_forest_dense_no10yrs = YRFForestDense_no10yrs.select([config['band_name_image']])\n",
    "# Map.addLayer(yrf_forest_dense_no10yrs,{'palette': ['#83ff5a']},'Low-Med Forest')\n",
    "\n",
    "high_forest_dense_no10yrs = HighForestDense_no10yrs.select(config['band_name_image'])\n",
    "# Map.addLayer(high_forest_dense_no10yrs,{'palette': ['#09ab0c']},'High- Density Forest')\n",
    "\n",
    "yrf_forest_dense_10yrs = YRFForestDense_10yrs.select([config['band_name_image']])\n",
    "# Map.addLayer(yrf_forest_dense_10yrs,{'palette': ['#ff0abe']},'Re-growth Low-Med Density Forest')\n",
    "\n",
    "high_forest_dense_10yrs = HighForestDense_10yrs.select([config['band_name_image']])\n",
    "# Map.addLayer(high_forest_dense_10yrs,{'palette': ['#ff0004']},'Re-growth High Density Forest')\n",
    "\n",
    "No_pass_historical_years_rule = tenyrule_edited.select([config['band_name_image']])\n",
    "# Map.addLayer(No_pass_historical_years_rule,{'palette': ['#ff8a1d']},'Historical deforestation no regrowth (3 or 10 years)')\n",
    "\n",
    "# since there are case water from mining (overlap 10 years rule with water), we should unmasked first\n",
    "unmasked10years = AOI_img.unmask().updateMask(No_pass_historical_years_rule.mask().Not()).clip(AOI)\n",
    "water_no_10yr = waterinAOI.And(unmasked10years).And(unmasked10years)\n",
    "Water_Un_plantable = ee.Image(assigning_band(config['band_name_image'],9,water_no_10yr)).select(config['band_name_image'])\n",
    "\n",
    "# Map.addLayer(Water_Un_plantable,{'palette': ['#1900ff']},'Water body (unplantable)')\n",
    "\n",
    "# Example band name to check\n",
    "band_name = config['band_name_image']\n",
    "\n",
    "# Select images if the band exists\n",
    "plantation_noGozone = select_band_if_exists(Plantation_noGozone, band_name)\n",
    "infrastructure_noGozone = select_band_if_exists(Infrastructure_noGozone, band_name)\n",
    "oilpalm_noGozone = select_band_if_exists(Oilpalm_noGozone, band_name)\n",
    "cropland_Gozone = select_band_if_exists(Cropland_Gozone, band_name)\n",
    "paddy_Gozone = select_band_if_exists(Paddy_Gozone, band_name)\n",
    "\n",
    "empty_image = ee.Image.constant(0).rename(config['band_name_image'])\n",
    "\n",
    "image_list_result = [\n",
    "    openland_gozone,\n",
    "    grassland_gozone,\n",
    "    shrubland_gozone,\n",
    "    high_forest_dense_no10yrs,\n",
    "    yrf_forest_dense_no10yrs,\n",
    "    high_forest_dense_10yrs,\n",
    "    yrf_forest_dense_10yrs,\n",
    "    No_pass_historical_years_rule,\n",
    "    Water_Un_plantable,\n",
    "    plantation_noGozone,\n",
    "    infrastructure_noGozone,\n",
    "    oilpalm_noGozone,\n",
    "    cropland_Gozone,\n",
    "    paddy_Gozone\n",
    "\n",
    "]\n",
    "\n",
    "# Remove None entries from the list\n",
    "image_list_result = [img for img in image_list_result if img is not None]\n",
    "\n",
    "# Create an ImageCollection from the list of images\n",
    "image_collection_result = ee.ImageCollection(image_list_result)\n",
    "\n",
    "# Apply the add_classes function to each image in the collection while merging them into the 'empty_image'\n",
    "result_collection_with_class = image_collection_result.map(lambda image: add_classes(image, empty_image))\n",
    "\n",
    "# Merge all the images in the result_collection using ee.ImageCollection.iterate()\n",
    "merged_image_result = ee.Image(result_collection_with_class.iterate(add_images, empty_image))\n",
    "\n",
    "# Cast the merged image to Int32 and set the original Class band name\n",
    "merged_image_result = merged_image_result.toInt32().rename('Class')\n",
    "merged_image_result = merged_image_result.clip(AOI)\n",
    "final_zone_map = merged_image_result\n",
    "\n",
    "arc_ops.adding_ee_to_arcgisPro(final_zone_map, vis_params_fcd_classified, f'Final_zone_ML_{algo_ml_selected}_Hansen')  # the naming probably will need to change, for some concistencies only so that you understand again later to read the codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Class']\n",
      "----\n",
      "['Class']\n",
      "----\n",
      "['Class']\n",
      "----\n",
      "['Class']\n",
      "----\n",
      "['Class']\n",
      "----\n",
      "['Class']\n",
      "----\n",
      "['Class']\n",
      "----\n",
      "['Class']\n",
      "----\n",
      "['Class', 'pixel']\n",
      "----\n",
      "['Class']\n",
      "----\n",
      "['Class']\n",
      "----\n",
      "['Class']\n",
      "----\n",
      "['Class']\n",
      "----\n",
      "['Class']\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for i in image_list_result:\n",
    "    print(i.bandNames().getInfo())\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Shrubland_gozone = shrub_masked.And(goZone_edited).select(['pixel'])\n",
    "Shrubland_gozone = ee.Image(assigning_band(config['band_name_image'],1,Shrubland_gozone))\n",
    "arc_ops.adding_ee_to_arcgisPro(Shrubland_gozone.randomVisualizer(),{},'Shrubland_gozone')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://earthengine.googleapis.com/v1/projects/ee-iwansetiawan/maps/cfd6d00f3129b288819a3a87e754e3fc-cc3e835c648791ff451016605e6bb581/tiles/{z}/{x}/{y}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<arcpy._mp.Layer object at 0x0000016E53FBA850>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Paddy_Gozone = paddy_irigated_masked.And(goZone_edited).select(['pixel'])\n",
    "Paddy_Gozone = ee.Image(assigning_band(config['band_name_image'],14,Paddy_Gozone))\n",
    "arc_ops.adding_ee_to_arcgisPro(Paddy_Gozone.randomVisualizer(),{},'Paddy_Gozone')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FCD']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HighForestDense.bandNames().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Class', 'pixel']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goZone_edited.bandNames().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "EEException",
     "evalue": "Image.select: Band pattern 'pixel' did not match any bands. Available bands: [classification]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mEEException\u001b[0m                               Traceback (most recent call last)",
      "In  \u001b[0;34m[59]\u001b[0m:\nLine \u001b[0;34m12\u001b[0m:    arc_ops.adding_ee_to_arcgisPro(final_zone, vis_params_fcd_classified, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mFinal_zone_ML_\u001b[39;49;00m\u001b[33m{\u001b[39;49;00malgo_ml_selected\u001b[33m}\u001b[39;49;00m\u001b[33m_Hansen\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)  \u001b[37m# the naming probably will need to change, for some concistencies only so that you understand again later to read the codes\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "File \u001b[0;34mC:\\Users\\q_bal\\Documents\\Github\\GEE_notebook_Forestry\\osi\\arcpy\\main.py\u001b[0m, in \u001b[0;32madding_ee_to_arcgisPro\u001b[0m:\nLine \u001b[0;34m56\u001b[0m:    map_id_dict = ee_image.getMapId(vis_params)\u001b[37m\u001b[39;49;00m\n",
      "File \u001b[0;34mC:\\Users\\q_bal\\AppData\\Local\\ESRI\\conda\\envs\\arcgispro-py3-cloned\\Lib\\site-packages\\ee\\image.py\u001b[0m, in \u001b[0;32mgetMapId\u001b[0m:\nLine \u001b[0;34m196\u001b[0m:   response = data.getMapId(request)\u001b[37m\u001b[39;49;00m\n",
      "File \u001b[0;34mC:\\Users\\q_bal\\AppData\\Local\\ESRI\\conda\\envs\\arcgispro-py3-cloned\\Lib\\site-packages\\ee\\data.py\u001b[0m, in \u001b[0;32mgetMapId\u001b[0m:\nLine \u001b[0;34m745\u001b[0m:   result = _execute_cloud_call(\u001b[37m\u001b[39;49;00m\n",
      "File \u001b[0;34mC:\\Users\\q_bal\\AppData\\Local\\ESRI\\conda\\envs\\arcgispro-py3-cloned\\Lib\\site-packages\\ee\\data.py\u001b[0m, in \u001b[0;32m_execute_cloud_call\u001b[0m:\nLine \u001b[0;34m405\u001b[0m:   \u001b[34mraise\u001b[39;49;00m _translate_cloud_exception(e)  \u001b[37m# pylint: disable=raise-missing-from\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[0;31mEEException\u001b[0m: Image.select: Band pattern 'pixel' did not match any bands. Available bands: [classification]\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
