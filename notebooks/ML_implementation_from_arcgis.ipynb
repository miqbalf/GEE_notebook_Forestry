{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-13T03:36:52.184230Z",
     "start_time": "2025-02-13T03:36:43.288473Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "root_dir = r\"Z:\\Shared drives\\TREEO BD Supply\\satellite_verification\\2025_notebooks_Satver\\20250205_Koop_Bali\\arcgis\\obia_segment_shift\\data_analysis.gdb\"  # Change to your workspace\n",
    "\n",
    "# do this outside arcgis pro - i dont know why arcgis resource have the error here\n",
    "df_training_fix_labeled = pd.read_csv(os.path.join(os.path.dirname(root_dir), 'training_ml_lu.csv'))\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier  # Example: Random Forest\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV  # For hyperparameter tuning\n",
    "\n",
    "# 1. Separate features (X) and labels (y)\n",
    "X = df_training_fix_labeled.drop('code_lu', axis=1)  # Features (all columns except 'code_lu')\n",
    "y = df_training_fix_labeled['code_lu']  # Labels ('code_lu' column)\n",
    "\n",
    "# 2. Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # 80% train, 20% test\n",
    "\n",
    "# 3. Scale the features (important for many models)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)  # Use the same scaler fitted on the training data\n",
    "\n",
    "# 4. Choose a model (Random Forest is a good starting point)\n",
    "model = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "\n",
    "# 5. Hyperparameter Tuning (GridSearchCV) - Optional but highly recommended\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],  # Test different numbers of trees\n",
    "    'max_depth': [None, 10, 20],  # Test different tree depths\n",
    "    'min_samples_split': [2, 5, 10],  # Test different minimum samples per split\n",
    "    'min_samples_leaf': [1, 2, 4]  # Test different minimum samples per leaf\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=3, scoring='accuracy', n_jobs=-1)  # cv=3 for 3-fold cross-validation, n_jobs=-1 to use all cores\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_  # Get the best model from grid search\n",
    "\n",
    "# 6. Train the model (using the best hyperparameters from GridSearch)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# 7. Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# 8. Evaluate the model\n",
    "print(classification_report(y_test, y_pred))  # Print classification report (precision, recall, F1-score)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# 9. (Optional) Save the trained model\n",
    "import joblib\n",
    "model_filename = \"trained_model.pkl\"  # Or any name you prefer\n",
    "joblib.dump(best_model, model_filename)\n",
    "print(f\"Model saved to: {model_filename}\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\q_bal\\.env\\treeo_ml\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.80      0.80      0.80         5\n",
      "         2.0       0.00      0.00      0.00         1\n",
      "         4.0       0.00      0.00      0.00         1\n",
      "         7.0       0.50      1.00      0.67         3\n",
      "         9.0       0.80      0.67      0.73         6\n",
      "\n",
      "    accuracy                           0.69        16\n",
      "   macro avg       0.42      0.49      0.44        16\n",
      "weighted avg       0.64      0.69      0.65        16\n",
      "\n",
      "Accuracy: 0.6875\n",
      "Model saved to: trained_model.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\q_bal\\.env\\treeo_ml\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\q_bal\\.env\\treeo_ml\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\q_bal\\.env\\treeo_ml\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T01:20:08.088414Z",
     "start_time": "2025-02-13T01:20:08.073228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "y = np.array([1.0, 2.0, 3.0, 4.0, 7.0, 9.0])\n",
    "\n",
    "# Step 1: Create a mapping from original labels to normalized labels\n",
    "unique_classes = np.unique(y)\n",
    "label_mapping = {original: normalized for normalized, original in enumerate(unique_classes)}\n",
    "print(\"Label Mapping:\", label_mapping)\n",
    "\n",
    "# Step 2: Transform the target variable `y` using the mapping\n",
    "y_normalized = np.array([label_mapping[val] for val in y])\n",
    "print(\"Original y:\", y)\n",
    "print(\"Normalized y:\", y_normalized)\n",
    "\n",
    "# Step 3: Store the mapping for later use\n",
    "# You can save this dictionary to a file or use it in your code\n",
    "# Example: Save to a JSON file\n",
    "import json\n",
    "with open(\"label_mapping.json\", \"w\") as f:\n",
    "    json.dump(label_mapping, f)\n",
    "\n",
    "# Step 4: Reverse the transformation (if needed)\n",
    "# Load the mapping (if saved to a file)\n",
    "with open(\"label_mapping.json\", \"r\") as f:\n",
    "    loaded_mapping = json.load(f)\n",
    "\n",
    "# Reverse the normalization\n",
    "y_original = np.array([list(loaded_mapping.keys())[list(loaded_mapping.values()).index(val)] for val in y_normalized])\n",
    "print(\"Reversed y:\", y_original)"
   ],
   "id": "5f3df719e4cbd2d2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping: {np.float64(1.0): 0, np.float64(2.0): 1, np.float64(3.0): 2, np.float64(4.0): 3, np.float64(7.0): 4, np.float64(9.0): 5}\n",
      "Original y: [1. 2. 3. 4. 7. 9.]\n",
      "Normalized y: [0 1 2 3 4 5]\n",
      "Reversed y: ['1.0' '2.0' '3.0' '4.0' '7.0' '9.0']\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T01:33:27.854733Z",
     "start_time": "2025-02-13T01:33:27.675800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "# Example dataset\n",
    "# Assuming df_training_fix_labeled is your DataFrame\n",
    "X = df_training_fix_labeled.drop('code_lu', axis=1)  # Features\n",
    "y = df_training_fix_labeled['code_lu']  # Original labels\n",
    "\n",
    "# Step 1: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Encode y_train and y_test\n",
    "encoder = LabelEncoder()\n",
    "y_train_encoded = encoder.fit_transform(y_train)  # Fit on y_train and transform y_train\n",
    "y_test_encoded = encoder.transform(y_test)  # Transform y_test using the same encoder\n",
    "class_weights = compute_sample_weight(class_weight='balanced', y=y_train_encoded)\n",
    "\n",
    "# Train the XGBoost model with class weights\n",
    "model = XGBClassifier(random_state=42)\n",
    "model.fit(X_train, y_train_encoded, sample_weight=class_weights)\n",
    "\n",
    "# Step 4: Make predictions\n",
    "y_pred_encoded = model.predict(X_test)\n",
    "\n",
    "# Step 5: Reverse the encoding for evaluation (if needed)\n",
    "y_pred_original = encoder.inverse_transform(y_pred_encoded)\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_original))  # Use original labels for evaluation\n",
    "print(f\"Accuracy: {accuracy_score(y_test_encoded, y_pred_encoded)}\")  # Use encoded labels for accuracy"
   ],
   "id": "35c97650025c0628",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.80      0.80      0.80         5\n",
      "         2.0       0.00      0.00      0.00         1\n",
      "         3.0       0.00      0.00      0.00         0\n",
      "         4.0       0.00      0.00      0.00         1\n",
      "         7.0       0.50      1.00      0.67         3\n",
      "         9.0       0.75      0.50      0.60         6\n",
      "\n",
      "    accuracy                           0.62        16\n",
      "   macro avg       0.34      0.38      0.34        16\n",
      "weighted avg       0.62      0.62      0.60        16\n",
      "\n",
      "Accuracy: 0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\q_bal\\.env\\treeo_ml\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\q_bal\\.env\\treeo_ml\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\q_bal\\.env\\treeo_ml\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\q_bal\\.env\\treeo_ml\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\q_bal\\.env\\treeo_ml\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\q_bal\\.env\\treeo_ml\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T01:41:33.813829Z",
     "start_time": "2025-02-13T01:41:30.337323Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier  # Import DecisionTreeClassifier (CART)\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Step 1: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "## Step 2: Encode y_train and y_test\n",
    "encoder = LabelEncoder()\n",
    "y_train_encoded = encoder.fit_transform(y_train)  # Fit on y_train and transform y_train\n",
    "y_test_encoded = encoder.transform(y_test)  # Transform y_test using the same encoder\n",
    "class_weights = compute_sample_weight(class_weight='balanced', y=y_train_encoded)\n",
    "\n",
    "# 3. Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 4. Use Decision Tree Classifier (CART)\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# 5. Hyperparameter Tuning (GridSearchCV)\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],  # Test different split criteria\n",
    "    'max_depth': [None, 5, 10, 15],  # Test different tree depths\n",
    "    'min_samples_split': [2, 5, 10],  # Test different minimum samples per split\n",
    "    'min_samples_leaf': [1, 2, 4]  # Test different minimum samples per leaf\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train_encoded)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# 6. Train the model\n",
    "best_model.fit(X_train, y_train_encoded)\n",
    "\n",
    "# 7. Make predictions\n",
    "y_pred_encoded = best_model.predict(X_test)\n",
    "\n",
    "# Step 5: Reverse the encoding for evaluation (if needed)\n",
    "y_pred_original = encoder.inverse_transform(y_pred_encoded)\n",
    "\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_original))  # Use original labels for evaluation\n",
    "print(f\"Accuracy: {accuracy_score(y_test_encoded, y_pred_encoded)}\")  # Use encoded labels for accuracy\n",
    "\n",
    "#... (Optional: Save the model)"
   ],
   "id": "8b4440b10c792cf5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\q_bal\\.env\\treeo_ml\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.80      0.80      0.80         5\n",
      "         2.0       0.00      0.00      0.00         1\n",
      "         4.0       0.00      0.00      0.00         1\n",
      "         7.0       0.50      1.00      0.67         3\n",
      "         9.0       1.00      0.50      0.67         6\n",
      "\n",
      "    accuracy                           0.62        16\n",
      "   macro avg       0.46      0.46      0.43        16\n",
      "weighted avg       0.72      0.62      0.62        16\n",
      "\n",
      "Accuracy: 0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\q_bal\\.env\\treeo_ml\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\q_bal\\.env\\treeo_ml\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\q_bal\\.env\\treeo_ml\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T03:36:58.330765Z",
     "start_time": "2025-02-13T03:36:58.125552Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# !pip install imbalanced-from collections import Counter\n",
    "from collections import Counter\n",
    "\n",
    "class_counts = Counter(y)\n",
    "print(class_counts)\n",
    "\n",
    "# 2. Encode the labels (y)\n",
    "encoder = LabelEncoder()\n",
    "y_encoded = encoder.fit_transform(y)\n",
    "\n",
    "# 3. Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# 4. Identify minority classes in the training set\n",
    "class_counts = Counter(y_train)  # Count occurrences in the training set\n",
    "minority_classes = [key for key, value in class_counts.items() if value < 10]  # Define minority classes (adjust threshold as needed)\n",
    "\n",
    "# # 5. Apply SMOTE to oversample minority classes in the training set\n",
    "# smote = SMOTE(random_state=42, k_neighbors=1)  # Use k_neighbors=2 to avoid the previous error\n",
    "# X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# 6. Scale the features (use the resampled training set)\n",
    "scaler = StandardScaler()\n",
    "# X_train_resampled = scaler.fit_transform(X_train_resampled)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 7. Use SVM Classifier (SVC)\n",
    "model = SVC(random_state=42)\n",
    "\n",
    "# 6. Hyperparameter Tuning (GridSearchCV)\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],  # Expanded range for C\n",
    "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],  # Added sigmoid kernel\n",
    "    'gamma': ['scale', 'auto', 0.1, 1, 10]  # Expanded range for gamma\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "# grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# 9. Train the model (using the best model from GridSearchCV and resampled data)\n",
    "# best_model.fit(X_train_resampled, y_train_resampled)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# 10. Make predictions\n",
    "y_pred_encoded = best_model.predict(X_test)\n",
    "\n",
    "# 11. Evaluate the model\n",
    "print(classification_report(y_test, y_pred_encoded))\n",
    "accuracy = accuracy_score(y_test, y_pred_encoded)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# 12. (Optional) Decode predictions\n",
    "y_pred_original = encoder.inverse_transform(y_pred_encoded)"
   ],
   "id": "fff58fed0f3e2f81",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1.0: 29, 9.0: 27, 7.0: 11, 2.0: 4, 3.0: 3, 4.0: 3})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91         5\n",
      "           1       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.60      1.00      0.75         3\n",
      "           5       0.80      0.67      0.73         6\n",
      "\n",
      "    accuracy                           0.75        16\n",
      "   macro avg       0.45      0.53      0.48        16\n",
      "weighted avg       0.67      0.75      0.70        16\n",
      "\n",
      "Accuracy: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\q_bal\\.env\\treeo_ml\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n",
      "C:\\Users\\q_bal\\.env\\treeo_ml\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\q_bal\\.env\\treeo_ml\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\q_bal\\.env\\treeo_ml\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T03:41:35.236291Z",
     "start_time": "2025-02-13T03:41:28.057672Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# 2. Encode the labels (y)\n",
    "encoder = LabelEncoder()\n",
    "y_encoded = encoder.fit_transform(y)\n",
    "\n",
    "# 3. Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# 4. Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 5. Define the deep learning model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),  # Correct input_shape\n",
    "    keras.layers.Dense(64, activation='relu'),  # Hidden layer\n",
    "    keras.layers.Dense(len(np.unique(y_encoded)), activation='softmax')  # Output layer\n",
    "])\n",
    "\n",
    "# 6. Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 7. Train the model\n",
    "model.fit(X_train, y_train, epochs=200, batch_size=32, validation_split=0.2)  # Add validation_split\n",
    "\n",
    "# 8. Make predictions\n",
    "y_pred_encoded = np.argmax(model.predict(X_test), axis=1)  # Use argmax for multi-class\n",
    "\n",
    "# 9. Evaluate the model\n",
    "print(classification_report(y_test, y_pred_encoded))\n",
    "accuracy = accuracy_score(y_test, y_pred_encoded)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# 10. (Optional) Decode predictions\n",
    "y_pred_original = encoder.inverse_transform(y_pred_encoded)"
   ],
   "id": "4a0de799e85d6995",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001A26FC01DA0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_train_function.<locals>.train_function at 0x000001A26FC01DA0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001A26FC01DA0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_train_function.<locals>.train_function at 0x000001A26FC01DA0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.9844 - accuracy: 0.0625WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001A26FC00D60> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_test_function.<locals>.test_function at 0x000001A26FC00D60>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001A26FC00D60> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_test_function.<locals>.test_function at 0x000001A26FC00D60>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2/2 [==============================] - 1s 133ms/step - loss: 2.0050 - accuracy: 0.0417 - val_loss: 1.9527 - val_accuracy: 0.0769\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.6376 - accuracy: 0.2292 - val_loss: 1.5882 - val_accuracy: 0.3077\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.3793 - accuracy: 0.5417 - val_loss: 1.3052 - val_accuracy: 0.6154\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.2004 - accuracy: 0.6042 - val_loss: 1.0829 - val_accuracy: 0.6154\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.0649 - accuracy: 0.6250 - val_loss: 0.9259 - val_accuracy: 0.7692\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.9539 - accuracy: 0.6667 - val_loss: 0.8183 - val_accuracy: 0.7692\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.8684 - accuracy: 0.7083 - val_loss: 0.7435 - val_accuracy: 0.7692\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8196 - accuracy: 0.7292 - val_loss: 0.6823 - val_accuracy: 0.7692\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7642 - accuracy: 0.7708 - val_loss: 0.6279 - val_accuracy: 0.7692\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7150 - accuracy: 0.7917 - val_loss: 0.5816 - val_accuracy: 0.8462\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6607 - accuracy: 0.8125 - val_loss: 0.5482 - val_accuracy: 0.8462\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6158 - accuracy: 0.8333 - val_loss: 0.5195 - val_accuracy: 0.8462\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5760 - accuracy: 0.8333 - val_loss: 0.5003 - val_accuracy: 0.8462\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5390 - accuracy: 0.8750 - val_loss: 0.4861 - val_accuracy: 0.9231\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5052 - accuracy: 0.8750 - val_loss: 0.4752 - val_accuracy: 0.9231\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.4715 - accuracy: 0.8750 - val_loss: 0.4599 - val_accuracy: 0.8462\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4404 - accuracy: 0.8958 - val_loss: 0.4452 - val_accuracy: 0.8462\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.4121 - accuracy: 0.8958 - val_loss: 0.4317 - val_accuracy: 0.8462\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3858 - accuracy: 0.8958 - val_loss: 0.4228 - val_accuracy: 0.8462\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3619 - accuracy: 0.8958 - val_loss: 0.4122 - val_accuracy: 0.8462\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3371 - accuracy: 0.9167 - val_loss: 0.4059 - val_accuracy: 0.8462\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3150 - accuracy: 0.9375 - val_loss: 0.4079 - val_accuracy: 0.8462\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2967 - accuracy: 0.9375 - val_loss: 0.4086 - val_accuracy: 0.8462\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2771 - accuracy: 0.9375 - val_loss: 0.4049 - val_accuracy: 0.8462\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.2584 - accuracy: 0.9375 - val_loss: 0.3975 - val_accuracy: 0.8462\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2406 - accuracy: 0.9583 - val_loss: 0.3943 - val_accuracy: 0.8462\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2267 - accuracy: 0.9583 - val_loss: 0.3989 - val_accuracy: 0.8462\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.2147 - accuracy: 0.9583 - val_loss: 0.4112 - val_accuracy: 0.8462\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1997 - accuracy: 0.9583 - val_loss: 0.4339 - val_accuracy: 0.8462\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1900 - accuracy: 0.9792 - val_loss: 0.4696 - val_accuracy: 0.8462\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1788 - accuracy: 0.9792 - val_loss: 0.4805 - val_accuracy: 0.8462\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1672 - accuracy: 0.9792 - val_loss: 0.4770 - val_accuracy: 0.8462\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1574 - accuracy: 0.9792 - val_loss: 0.4691 - val_accuracy: 0.8462\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1476 - accuracy: 0.9792 - val_loss: 0.4582 - val_accuracy: 0.8462\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1401 - accuracy: 0.9792 - val_loss: 0.4517 - val_accuracy: 0.8462\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1319 - accuracy: 0.9792 - val_loss: 0.4578 - val_accuracy: 0.8462\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1248 - accuracy: 0.9792 - val_loss: 0.4605 - val_accuracy: 0.8462\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1177 - accuracy: 0.9792 - val_loss: 0.4628 - val_accuracy: 0.8462\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1115 - accuracy: 0.9792 - val_loss: 0.4676 - val_accuracy: 0.8462\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1053 - accuracy: 0.9792 - val_loss: 0.4707 - val_accuracy: 0.8462\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1000 - accuracy: 0.9792 - val_loss: 0.4761 - val_accuracy: 0.8462\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0951 - accuracy: 1.0000 - val_loss: 0.4917 - val_accuracy: 0.8462\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0902 - accuracy: 1.0000 - val_loss: 0.4954 - val_accuracy: 0.8462\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0860 - accuracy: 1.0000 - val_loss: 0.4974 - val_accuracy: 0.8462\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0814 - accuracy: 1.0000 - val_loss: 0.5016 - val_accuracy: 0.8462\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0772 - accuracy: 1.0000 - val_loss: 0.5051 - val_accuracy: 0.8462\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0743 - accuracy: 1.0000 - val_loss: 0.5095 - val_accuracy: 0.8462\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0708 - accuracy: 1.0000 - val_loss: 0.5206 - val_accuracy: 0.8462\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0674 - accuracy: 1.0000 - val_loss: 0.5354 - val_accuracy: 0.8462\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0641 - accuracy: 1.0000 - val_loss: 0.5497 - val_accuracy: 0.8462\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0616 - accuracy: 1.0000 - val_loss: 0.5576 - val_accuracy: 0.8462\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0584 - accuracy: 1.0000 - val_loss: 0.5502 - val_accuracy: 0.8462\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0562 - accuracy: 1.0000 - val_loss: 0.5396 - val_accuracy: 0.8462\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0538 - accuracy: 1.0000 - val_loss: 0.5399 - val_accuracy: 0.8462\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0514 - accuracy: 1.0000 - val_loss: 0.5367 - val_accuracy: 0.8462\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0492 - accuracy: 1.0000 - val_loss: 0.5469 - val_accuracy: 0.8462\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0467 - accuracy: 1.0000 - val_loss: 0.5629 - val_accuracy: 0.8462\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0444 - accuracy: 1.0000 - val_loss: 0.5886 - val_accuracy: 0.8462\n",
      "Epoch 59/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0425 - accuracy: 1.0000 - val_loss: 0.6204 - val_accuracy: 0.8462\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0410 - accuracy: 1.0000 - val_loss: 0.6481 - val_accuracy: 0.8462\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0400 - accuracy: 1.0000 - val_loss: 0.6645 - val_accuracy: 0.8462\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0388 - accuracy: 1.0000 - val_loss: 0.6629 - val_accuracy: 0.8462\n",
      "Epoch 63/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0370 - accuracy: 1.0000 - val_loss: 0.6383 - val_accuracy: 0.8462\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0352 - accuracy: 1.0000 - val_loss: 0.6180 - val_accuracy: 0.8462\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 0.6066 - val_accuracy: 0.8462\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 0.6097 - val_accuracy: 0.8462\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 0.6317 - val_accuracy: 0.8462\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 0.6550 - val_accuracy: 0.8462\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.6687 - val_accuracy: 0.8462\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 0.6790 - val_accuracy: 0.8462\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 0.6808 - val_accuracy: 0.8462\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0260 - accuracy: 1.0000 - val_loss: 0.6712 - val_accuracy: 0.8462\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 0.6681 - val_accuracy: 0.8462\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 0.6650 - val_accuracy: 0.8462\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0233 - accuracy: 1.0000 - val_loss: 0.6562 - val_accuracy: 0.8462\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.6566 - val_accuracy: 0.8462\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.6729 - val_accuracy: 0.8462\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.6985 - val_accuracy: 0.8462\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.7206 - val_accuracy: 0.8462\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.7248 - val_accuracy: 0.8462\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.7183 - val_accuracy: 0.8462\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.7191 - val_accuracy: 0.8462\n",
      "Epoch 83/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.7133 - val_accuracy: 0.8462\n",
      "Epoch 84/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.7146 - val_accuracy: 0.8462\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.7200 - val_accuracy: 0.8462\n",
      "Epoch 86/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.7275 - val_accuracy: 0.8462\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.7388 - val_accuracy: 0.8462\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.7434 - val_accuracy: 0.8462\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.7525 - val_accuracy: 0.8462\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.7662 - val_accuracy: 0.8462\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.7747 - val_accuracy: 0.8462\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.7832 - val_accuracy: 0.8462\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.7882 - val_accuracy: 0.8462\n",
      "Epoch 94/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.7855 - val_accuracy: 0.8462\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.7932 - val_accuracy: 0.8462\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.8039 - val_accuracy: 0.8462\n",
      "Epoch 97/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.8145 - val_accuracy: 0.8462\n",
      "Epoch 98/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.8207 - val_accuracy: 0.8462\n",
      "Epoch 99/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.8208 - val_accuracy: 0.8462\n",
      "Epoch 100/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.8156 - val_accuracy: 0.8462\n",
      "Epoch 101/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.8123 - val_accuracy: 0.8462\n",
      "Epoch 102/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.8133 - val_accuracy: 0.8462\n",
      "Epoch 103/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.8184 - val_accuracy: 0.8462\n",
      "Epoch 104/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.8213 - val_accuracy: 0.8462\n",
      "Epoch 105/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.8309 - val_accuracy: 0.8462\n",
      "Epoch 106/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.8345 - val_accuracy: 0.8462\n",
      "Epoch 107/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.8398 - val_accuracy: 0.8462\n",
      "Epoch 108/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.8515 - val_accuracy: 0.8462\n",
      "Epoch 109/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.8603 - val_accuracy: 0.8462\n",
      "Epoch 110/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.8650 - val_accuracy: 0.7692\n",
      "Epoch 111/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.8637 - val_accuracy: 0.7692\n",
      "Epoch 112/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.8667 - val_accuracy: 0.7692\n",
      "Epoch 113/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.8690 - val_accuracy: 0.7692\n",
      "Epoch 114/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.8715 - val_accuracy: 0.8462\n",
      "Epoch 115/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.8751 - val_accuracy: 0.8462\n",
      "Epoch 116/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.8808 - val_accuracy: 0.8462\n",
      "Epoch 117/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.8924 - val_accuracy: 0.7692\n",
      "Epoch 118/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.9031 - val_accuracy: 0.7692\n",
      "Epoch 119/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.9084 - val_accuracy: 0.7692\n",
      "Epoch 120/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.9110 - val_accuracy: 0.7692\n",
      "Epoch 121/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.9105 - val_accuracy: 0.7692\n",
      "Epoch 122/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.9073 - val_accuracy: 0.7692\n",
      "Epoch 123/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.9056 - val_accuracy: 0.7692\n",
      "Epoch 124/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.9052 - val_accuracy: 0.7692\n",
      "Epoch 125/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.9107 - val_accuracy: 0.7692\n",
      "Epoch 126/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.9141 - val_accuracy: 0.7692\n",
      "Epoch 127/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.9170 - val_accuracy: 0.7692\n",
      "Epoch 128/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.9145 - val_accuracy: 0.7692\n",
      "Epoch 129/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.9144 - val_accuracy: 0.7692\n",
      "Epoch 130/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.9158 - val_accuracy: 0.7692\n",
      "Epoch 131/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.9232 - val_accuracy: 0.7692\n",
      "Epoch 132/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.9288 - val_accuracy: 0.7692\n",
      "Epoch 133/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.9284 - val_accuracy: 0.7692\n",
      "Epoch 134/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.9231 - val_accuracy: 0.7692\n",
      "Epoch 135/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.9203 - val_accuracy: 0.7692\n",
      "Epoch 136/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.9215 - val_accuracy: 0.7692\n",
      "Epoch 137/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.9261 - val_accuracy: 0.7692\n",
      "Epoch 138/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.9336 - val_accuracy: 0.7692\n",
      "Epoch 139/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.9389 - val_accuracy: 0.7692\n",
      "Epoch 140/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.9448 - val_accuracy: 0.7692\n",
      "Epoch 141/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.9434 - val_accuracy: 0.7692\n",
      "Epoch 142/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.9421 - val_accuracy: 0.7692\n",
      "Epoch 143/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.9435 - val_accuracy: 0.7692\n",
      "Epoch 144/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.9493 - val_accuracy: 0.7692\n",
      "Epoch 145/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.9579 - val_accuracy: 0.7692\n",
      "Epoch 146/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.9664 - val_accuracy: 0.7692\n",
      "Epoch 147/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.9677 - val_accuracy: 0.7692\n",
      "Epoch 148/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.9682 - val_accuracy: 0.7692\n",
      "Epoch 149/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.9710 - val_accuracy: 0.7692\n",
      "Epoch 150/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.9734 - val_accuracy: 0.7692\n",
      "Epoch 151/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.9750 - val_accuracy: 0.7692\n",
      "Epoch 152/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.9802 - val_accuracy: 0.7692\n",
      "Epoch 153/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.9893 - val_accuracy: 0.7692\n",
      "Epoch 154/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.9952 - val_accuracy: 0.7692\n",
      "Epoch 155/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.9958 - val_accuracy: 0.7692\n",
      "Epoch 156/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.9930 - val_accuracy: 0.7692\n",
      "Epoch 157/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.9953 - val_accuracy: 0.7692\n",
      "Epoch 158/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.9991 - val_accuracy: 0.7692\n",
      "Epoch 159/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.9997 - val_accuracy: 0.7692\n",
      "Epoch 160/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.0024 - val_accuracy: 0.7692\n",
      "Epoch 161/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.0060 - val_accuracy: 0.7692\n",
      "Epoch 162/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.0084 - val_accuracy: 0.7692\n",
      "Epoch 163/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.0136 - val_accuracy: 0.7692\n",
      "Epoch 164/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.0133 - val_accuracy: 0.7692\n",
      "Epoch 165/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.0131 - val_accuracy: 0.7692\n",
      "Epoch 166/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.0177 - val_accuracy: 0.7692\n",
      "Epoch 167/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.0262 - val_accuracy: 0.7692\n",
      "Epoch 168/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.0322 - val_accuracy: 0.7692\n",
      "Epoch 169/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.0349 - val_accuracy: 0.7692\n",
      "Epoch 170/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.0364 - val_accuracy: 0.7692\n",
      "Epoch 171/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.0388 - val_accuracy: 0.7692\n",
      "Epoch 172/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.0404 - val_accuracy: 0.7692\n",
      "Epoch 173/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.0424 - val_accuracy: 0.7692\n",
      "Epoch 174/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.0419 - val_accuracy: 0.7692\n",
      "Epoch 175/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.0416 - val_accuracy: 0.7692\n",
      "Epoch 176/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.0426 - val_accuracy: 0.7692\n",
      "Epoch 177/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.0469 - val_accuracy: 0.7692\n",
      "Epoch 178/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.0517 - val_accuracy: 0.7692\n",
      "Epoch 179/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.0550 - val_accuracy: 0.7692\n",
      "Epoch 180/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.0540 - val_accuracy: 0.7692\n",
      "Epoch 181/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.0547 - val_accuracy: 0.7692\n",
      "Epoch 182/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.0541 - val_accuracy: 0.7692\n",
      "Epoch 183/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.0545 - val_accuracy: 0.7692\n",
      "Epoch 184/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.0560 - val_accuracy: 0.7692\n",
      "Epoch 185/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.0615 - val_accuracy: 0.7692\n",
      "Epoch 186/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.0657 - val_accuracy: 0.7692\n",
      "Epoch 187/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.0687 - val_accuracy: 0.7692\n",
      "Epoch 188/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.0721 - val_accuracy: 0.7692\n",
      "Epoch 189/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.0757 - val_accuracy: 0.7692\n",
      "Epoch 190/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.0790 - val_accuracy: 0.7692\n",
      "Epoch 191/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.0822 - val_accuracy: 0.7692\n",
      "Epoch 192/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.0849 - val_accuracy: 0.7692\n",
      "Epoch 193/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.0865 - val_accuracy: 0.7692\n",
      "Epoch 194/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.0918 - val_accuracy: 0.7692\n",
      "Epoch 195/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.1006 - val_accuracy: 0.7692\n",
      "Epoch 196/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.1048 - val_accuracy: 0.7692\n",
      "Epoch 197/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.1065 - val_accuracy: 0.7692\n",
      "Epoch 198/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.1042 - val_accuracy: 0.7692\n",
      "Epoch 199/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.1027 - val_accuracy: 0.7692\n",
      "Epoch 200/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.1016 - val_accuracy: 0.7692\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001A26FD01120> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001A26FD01120>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001A26FD01120> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001A26FD01120>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91         5\n",
      "           1       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.50      1.00      0.67         3\n",
      "           5       0.75      0.50      0.60         6\n",
      "\n",
      "    accuracy                           0.69        16\n",
      "   macro avg       0.42      0.50      0.44        16\n",
      "weighted avg       0.64      0.69      0.63        16\n",
      "\n",
      "Accuracy: 0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\q_bal\\.env\\treeo_ml\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\q_bal\\.env\\treeo_ml\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\q_bal\\.env\\treeo_ml\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T03:37:02.711292Z",
     "start_time": "2025-02-13T03:37:02.706156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ],
   "id": "c19a1cda8f969ef1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T03:37:04.790233Z",
     "start_time": "2025-02-13T03:37:04.784320Z"
    }
   },
   "cell_type": "code",
   "source": "tf.test.is_built_with_cuda()",
   "id": "d5ad4ec271ede7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T02:27:56.699821Z",
     "start_time": "2025-02-13T02:27:56.694817Z"
    }
   },
   "cell_type": "code",
   "source": "# !pip install tensorflow",
   "id": "f49584d117bf17ea",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T01:14:08.138732Z",
     "start_time": "2025-02-13T01:14:08.134240Z"
    }
   },
   "cell_type": "code",
   "source": "# !pip install xgboost",
   "id": "1159793e5e1036b",
   "outputs": [],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
